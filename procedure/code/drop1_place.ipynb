{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2822739-8f2f-4429-8aad-f005f7e9a341",
   "metadata": {},
   "source": [
    "# Runs !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59be0af2-e854-4fe0-ae3f-bde61b44d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "import pysal as ps\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import zscore as ZSCORE\n",
    "from scipy.stats import rankdata\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# sovi compute script\n",
    "# import sys\n",
    "# sys.path.append(os.path.join(os.getcwd(),'code'))\n",
    "from spss_pca import SPSS_PCA\n",
    "# import compute_sovis\n",
    "\n",
    "# outPath=compute_sovis.outPath\n",
    "\n",
    "def dropAny(inputs,scores,drop=1,subset=None,netContrib=None,return_drop_rank=False):\n",
    "\n",
    "    \"\"\"\n",
    "    inputs, the input variables, i.e. compute_sovis.USA_All\n",
    "\n",
    "    scores, the SoVI outputs containing scores and ranks i.e. compute_sovis.USA_Sovi_Score\n",
    "\n",
    "    subset: list of GEOIDs for subset (use for FEMA region or state)\n",
    "\n",
    "    netContrib: i.e. compute_sovis.variable_ranks\n",
    "    \"\"\"\n",
    "\n",
    "    if not subset is None:\n",
    "        scores=scores[scores[scores.columns[len(scores.columns)-1]].astype('str').str.contains(subset)] # scores for region id\n",
    "        inputs=inputs[inputs.index.isin(scores[scores.columns[len(scores.columns)-1]].index)] # inputs for subset\n",
    "\n",
    "    # the data without no 1\n",
    "    drop_no1=inputs.drop(drop)\n",
    "\n",
    "    # preserve GEOIDs as an index\n",
    "    # for computed SoVI\n",
    "    geoLevels=drop_no1.Geo_FIPS\n",
    "\n",
    "    #Compute drop \"number one\"\n",
    "    pca = SPSS_PCA(drop_no1.drop(['Geo_FIPS', 'stateID'], axis = 1, inplace = False), reduce=True, varimax=True)\n",
    "    sovi_actual = pca.scores_rot.sum(1)\n",
    "    sovi_actual = pd.DataFrame(sovi_actual, index=geoLevels, columns=['sovi'])\n",
    "    drop1p_score = sovi_actual.values # SoVI score\n",
    "\n",
    "    if netContrib is None: # no net contrib var's specified, compute county ranks\n",
    "\n",
    "        # preserve the original county ranks\n",
    "        # also for computing change in rank...\n",
    "        orig_rank=scores.drop(drop)['rank']\n",
    "\n",
    "        # add SoVI ranks for run\n",
    "        drop1p_rank = pd.Series([i[0] for i in sovi_actual.values],index=geoLevels).rank(ascending=False)\n",
    "\n",
    "        obs_rchg_drop1=pd.DataFrame({'orig_rank':orig_rank,'drop1p_rank':drop1p_rank},index=orig_rank.index)\n",
    "        obs_rchg_drop1=obs_rchg_drop1.apply(lambda x: x.astype('int'),axis=1) # ensure all ints\n",
    "        obs_rchg_drop1['rank_chg']=obs_rchg_drop1.orig_rank-obs_rchg_drop1.drop1p_rank\n",
    "\n",
    "        return obs_rchg_drop1\n",
    "\n",
    "    else: # net contribution\n",
    "\n",
    "        #variable rank using absolute value\n",
    "        rankContrib = abs(netContrib).apply(rankdata, axis=0, method='average')\n",
    "        rankContrib = (28-rankContrib) + 1\n",
    "\n",
    "        #Construct table to hold the results of the drop one analysis\n",
    "        #Sort variable list based on importance rank.\n",
    "        if not subset:\n",
    "            varRanks = rankContrib['USA'].copy() #have to make a copy to sort index\n",
    "            varRanks.sort('USA')\n",
    "        else:\n",
    "            varRanks = rankContrib[subset].copy() #have to make a copy to sort index\n",
    "            varRanks.sort(subset)\n",
    "\n",
    "        # recompute net contribution for drop no1\n",
    "        Drop1_NetContrib = pd.Series(data=pca.weights_rot.sum(1), index=drop_no1.columns.drop(['Geo_FIPS', 'stateID']))\n",
    "        Drop1_NetContrib = Drop1_NetContrib.transpose()\n",
    "        Drop1_NetContrib=Drop1_NetContrib.convert_objects(convert_numeric=True)\n",
    "        Drop1_NetContrib = Drop1_NetContrib.apply(lambda x: np.round(x, 2))\n",
    "        Drop1_NetContrib = Drop1_NetContrib.rank(ascending=False)\n",
    "\n",
    "        Drop1_NetContrib=Drop1_NetContrib[varRanks.index] # sort values by original index ranking\n",
    "\n",
    "        nc_chg_drop1p=pd.DataFrame({'orig_rank':varRanks,'drop1p_rank':Drop1_NetContrib})\n",
    "        nc_chg_drop1p=nc_chg_drop1p.apply(lambda x: x.astype('int'),axis=1) # ensure all ints\n",
    "        nc_chg_drop1p['rank_chg']=nc_chg_drop1p.orig_rank-nc_chg_drop1p.drop1p_rank\n",
    "\n",
    "        return nc_chg_drop1p\n",
    "\n",
    "def rankChgTable(inputs,scores,obs_names,subset=None,top=5,cor=False,drop=1,verbose=True):\n",
    "\n",
    "    dropany_result=dropAny(inputs=inputs,scores=scores,subset=subset,drop=drop)\n",
    "\n",
    "    # ensure GEOID column in place\n",
    "    # assumes missing GEOID values stored in df index\n",
    "    if not 'geoFIPS' in dropany_result:\n",
    "        dropany_result['geoFIPS']=dropany_result.index\n",
    "\n",
    "    # merge dropany results with obs names\n",
    "    rctab=dropany_result.merge(obs_names,on='geoFIPS')\n",
    "\n",
    "    # print the spearman rank correlation if specified\n",
    "    if cor:\n",
    "        spearcor=spearmanr(rctab.drop1p_rank,rctab.orig_rank)\n",
    "        if verbose:\n",
    "            print(\"Spearman Rank Correlation: \"+str(np.round(spearcor[0],5)),\"\\np-value: \"+str(np.round(spearcor[1],4)))\n",
    "            print('\\n')\n",
    "\n",
    "    # dropped obs rank\n",
    "    drop_co=obs_names[obs_names.geoFIPS.str.contains(drop)]\n",
    "    drop_co['orig_rank']=scores.ix[drop]['rank']\n",
    "\n",
    "    # assemble table for original ranks\n",
    "    orrk=rctab[rctab.orig_rank<=top].ix[:,['geoFIPS','orig_rank','NAME']]\n",
    "\n",
    "    if int(drop_co.orig_rank)<=top: # append dropped obs to table if top-ranked\n",
    "        orrk=drop_co.append(orrk)\n",
    "\n",
    "    orrk=orrk.sort_values('orig_rank')\n",
    "    orrk['Top_Orig']=orrk.NAME+\" (\"+orrk.orig_rank.astype('int').astype('str')+\")\"\n",
    "    orrk.index=[i+1 for i in range(0,top)]\n",
    "    orrk.ix[:,['NAME','Top_Orig']]\n",
    "\n",
    "    # assemble table for dropany ranks\n",
    "    d1rk=rctab[rctab.drop1p_rank<=top].ix[:,['geoFIPS','drop1p_rank','orig_rank','NAME']].sort_values('drop1p_rank')\n",
    "    d1rk['Top_dropany']=d1rk.NAME+\" (\"+d1rk.orig_rank.astype('int').astype('str')+\")\"\n",
    "    d1rk.index=[i+1 for i in range(0,top)]\n",
    "    d1rk.ix[:,['NAME','Top_dropany']]\n",
    "\n",
    "    # return the tables combined\n",
    "    return pd.DataFrame({'All_Counties':orrk.Top_Orig,'Drop_1':d1rk.Top_dropany})\n",
    "\n",
    "# wrap to a function\n",
    "def dropCors(inputs,scores,subset=None):\n",
    "\n",
    "    cors=[]\n",
    "\n",
    "    if subset is None:\n",
    "        geo_idx=scores.index.values\n",
    "    else:\n",
    "        geo_idx=scores[scores[scores.columns[len(scores.columns)-1]].astype('str').str.contains(subset)].index.values\n",
    "\n",
    "    for i in geo_idx:\n",
    "        drop_i=dropAny(inputs=inputs,scores=scores,subset=subset,drop=i)\n",
    "        cor=spearmanr(drop_i.drop1p_rank,drop_i.orig_rank)\n",
    "        cors.append(cor[0])\n",
    "\n",
    "    return pd.Series(cors,index=geo_idx)\n",
    "\n",
    "## function for plotting rank quantile moves\n",
    "\n",
    "def rankQuantileMoves(inputs,scores,drop,subset=None,verbose=True):\n",
    "    da=dropAny(inputs=inputs,scores=scores,subset=subset,drop=drop)\n",
    "    if verbose:\n",
    "        print(ps.Quantiles(da.orig_rank)) # quantile breaks key\n",
    "        print('\\n')\n",
    "    r0=ps.Quantiles(da.orig_rank).yb\n",
    "    r1=ps.Quantiles(da.drop1p_rank).yb\n",
    "    moves_raw=pd.DataFrame({'r0':r0,'r1':r1}).groupby(['r0','r1']).size().unstack(fill_value=0)\n",
    "    return np.round(moves_raw.apply(lambda x: x/sum(x),axis=1),2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
