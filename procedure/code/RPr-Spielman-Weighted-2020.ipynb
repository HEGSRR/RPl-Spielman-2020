{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ccb0c41-8caa-4d84-835d-d297ff776126",
   "metadata": {},
   "source": [
    "# Reproduction of Spielman et al.’s 2020 Evaluation of the Social Vulnerability Index\n",
    "### Authors\n",
    "\n",
    "- Liam Smith\\*, lwsmith@middlebury.edu, @Liam-W-Smith, Middlebury College\n",
    "- Joseph Holler, josephh@middlebury.edu , @josephholler, [ORCID link](https://orcid.org/0000-0002-2381-2699), Middlebury College\n",
    "\n",
    "\\* Corresponding author and creator\n",
    "\n",
    "Version 1.1 | Created 2023-07-12 | Last Updated 2023-07-21  \n",
    "\n",
    "### Abstract\n",
    "\n",
    "This study is a *reproduction* of:\n",
    "\n",
    "> Spielman, S. E., Tuccillo, J., Folch, D. C., Schweikert, A., Davies, R., Wood, N., & Tate, E. (2020). Evaluating Social Vulnerability Indicators: Criteria and their Application to the Social Vulnerability Index. Natural Hazards, 100(1), 417–436. https://doi.org/10.1007/s11069-019-03820-z\n",
    "\n",
    "The Spielman et al. (2020) paper is in turn a replication of:\n",
    "\n",
    "> Cutter, S. L., Boruff, B. J., & Shirley, W. L. (2003). Social vulnerability to environmental hazards. Social Science Quarterly, 84(2), 242–261. https://doi.org/10.1111/1540-6237.8402002\n",
    "\n",
    "Spielman et al. (2020) developed methods to evaluate the internal consistency and construct validity of the Cutter, Boruff and Shirley (2003) Social Vulnerability Index (SoVI).\n",
    "First, they reproduce a national SoVI model and validate it against an SPSS procedure provided by the original research group (Hazards Vulnerability Research Institute at University of South Carolina).\n",
    "The original SoVI uses 42 independent z-score normalized variables from the U.S. Census, reduces the data to factors using Principal Components Analysis, selects the first eleven factors, inverts factors with inverse relationships to social vulnerability, and sums the factors together to produce a SoVI score.\n",
    "The reproduced SoVI model was slightly different than the original model due to changes in U.S. Census data, using only 28 variables.\n",
    "\n",
    "Spielman et al. modify the geographic extent of the SoVI calculation by calculating SoVI on a national extent, and then recalculating for each of ten Federal Emergency Management Agency (FEMA) regions, and again for a single state or cluster of states within each of the ten regions, resulting in 21 total indices.\n",
    "Internal consistency is assessed by calculating the spearman rank correlation coefficient of the SoVI score for counties in the state model compared to the FEMA region model and national model.\n",
    "Construct validity is assessed by summing the loadings for each input variable across the PCA factors in each model and calculating the variables sign (positive/negative) and the rank of the variable's total loading compared to the other variables.\n",
    "These signs and ranks are summarized across all 21 versions of the SoVI model with regard to the number of times the sign is different from the national model and the distributions of ranks.\n",
    "\n",
    "In this reproduction study, we attempt to reproduce identical SoVI model outputs for each of the 21 models in the original study.\n",
    "We will compare these outputs to data files in Spielman et al.'s GitHub repository.\n",
    "We will also attempt to reproduce identical results of internal consistency analysis (figure 1 and table 2) and construct validity analysis (figure 2) from Spielman et al.'s paper.\n",
    "We succeed in reproducing identical SoVI model outputs, but find slight discrepancies in our figures and tables.\n",
    "\n",
    "The code in this Jupyter notebook report is adapted from Spielman et al.'s GitHub repository.\n",
    "The original study states the intended open source permissions in the acknowledgements: \"To facilitate advances to current practice and to allow replication of our results, all of the code and data used in this analysis is open source and available at (https://github.com/geoss/sovi-validity).\n",
    "Funding was provided by the US National Science Foundation (Award No. 1333271) and the U.S. Geological Survey Land Change Science Program.\"\n",
    "\n",
    "### Keywords\n",
    "\n",
    "Social vulnerability, social indicators, Principal Component Analysis, reproducibility\n",
    "\n",
    "## Study design\n",
    "\n",
    "We computationally reproduce Spielman et al.'s original work using the code provided in their Github repository (https://github.com/geoss/sovi-validity), adapting their code to run in an updated Python environment using current package versions.\n",
    "We make all of our work available online using the HEGSRR [reproducible research compendium template](https://github.com/HEGSRR/HEGSRR-Template).\n",
    "\n",
    "The original paper was a replication study testing the sensitivity of SoVI to changes in geographic extent.\n",
    "Spielman et al. addressed the following hypotheses in their work:\n",
    "\n",
    "> OR-H1: SoVI is internally inconsistent.\n",
    "\n",
    "To address this hypothesis, Spielman et al. illustrated that SoVI is not robust to changes in geographic extent by calculating SoVI scores for ten selected states or groups of states on three geographic extents: national, FEMA region, and state(s).\n",
    "The counties within the state(s) of interest were then selected and ranked according to their SoVI score.\n",
    "OR-H1 was tested by calculating Spearman's rank correlation between the state and FEMA region models and between the state and national models.\n",
    "\n",
    "> OR-H2: SoVI is theoretically inconsistent.\n",
    "\n",
    "To address this hypothesis, Spielman et al. used the same SoVI models as described under OR-H1.\n",
    "For each model, they summed all of the PCA factors together to determine the net influence of each variable in each model.\n",
    "Then they recorded the signs of each variable and calculated the number of deviations of the ten state and FEMA region models from the national model.\n",
    "They also ranked the variables by absolute value for each model and calculated summary statistics regarding the distribution of ranks for each variable amongst all models.\n",
    "Spielman et al. did not use a particular statistical method to test OR-H2, but illustrated substantial disagreements between variable rankings and signs amongst the 21 SoVI models.\n",
    "\n",
    "For our reproduction, we address the following three hypotheses:\n",
    "\n",
    "> RPr-H1: Reproduced SoVI model scores and other reproduced output datasets are not identical to the original study SoVI model scores and provided output datasets for each of the 21 SoVI models.\n",
    "\n",
    "> RPr-H2: Reproduced figures and tables for the internal consistency analysis are not identical to the figures and tables (figure 1 and table 2) of the original study.\n",
    "\n",
    "> RPr-H3: For the theoretical consistency analysis, reproduced direction reversals and min, average, and max SoVI rank value of 28 demographic variables are not identical to the direction reversals and min, average, and max SoVI rank values shown in figure 2 of the original study.\n",
    "\n",
    "\n",
    "We answer these questions by working through Spielman et al.'s code line by line in an updated python coding environment.\n",
    "To improve reproducibility, we reorganize Spielman's repository into the Template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences (doi:10.17605/OSF.IO/W29MQ) and use one Jupyter notebook for the reproduction report and code.\n",
    "We catalogue barriers to reproducibility and make improvements wherever possible.\n",
    "\n",
    "Disclaimer: we worked with the data and code before writing this report, so there is no pre-registration of the analysis plan.\n",
    "We originally intended to publish only a replication of this study; we did not anticipate publishing a reproduction until we spent some time working with the code.\n",
    "\n",
    "#### Spatio-temporal metadata\n",
    "\n",
    "- `Spatial Coverage`: United States, excluding Puerto Rico\n",
    "- `Spatial Resolution`: Counties and county equivalents\n",
    "- `Spatial Reference System`: EPSG:4269\n",
    "- `Temporal Coverage`: 2008 - 2012 (data is the 2012 5-year ACS)\n",
    "- `Temporal Resolution`: One-time measurement, does not address change over time\n",
    "\n",
    "## Materials and procedure\n",
    "\n",
    "### Computational environment\n",
    "\n",
    "Currently, we are using a [2020 MacBook Pro](https://support.apple.com/kb/SP818?locale=en_US) running on macOS Ventura 13.3.1.\n",
    "We anticipate collaborators working on the project from different computers and different operating systems, and we seek to containerize the project so that scripts can be run on many different machines.\n",
    "\n",
    "The original study used Python for their analysis, so we reproduce their results in Python, using a containerized conda environment.\n",
    "This environment consists of Python 3.9.16 and the software packages listed in [requirements.txt](../environment/requirements.txt)\n",
    "\n",
    "To set up this environment on another machine, one should install the correct version of Python and run the cell below to install the correct package versions.\n",
    "If a user wishes to create a self-contained environment, they should explore [venv](https://docs.python.org/3/library/venv.html), [conda](https://docs.conda.io/en/latest/), or [pipenv](https://pipenv.pypa.io/en/latest/) virtual environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8368471f-7098-4d60-bbc9-353e50def1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# report python version and install required packages\n",
    "# switch if statement from True to False once packages have been installed\n",
    "if True:\n",
    "    !python -V\n",
    "    !pip install -r ../environment/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113c5897-4a59-45ed-9dfb-df517762143a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import modules, define directories\n",
    "import pygris\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pygris.data import get_census\n",
    "from pygris import counties\n",
    "from pyhere import here\n",
    "import numpy as np\n",
    "import libpysal as lps\n",
    "import lxml\n",
    "import tabulate\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats.mstats import zscore as ZSCORE\n",
    "from scipy.stats import rankdata\n",
    "import mdp as MDP\n",
    "from operator import itemgetter\n",
    "import copy\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import patheffects as pe\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from IPython.display import Markdown, Latex\n",
    "\n",
    "pd.set_option(\"chained_assignment\", None)\n",
    "\n",
    "path = {\n",
    "    \"dscr\": here(\"data\", \"scratch\"),\n",
    "    \"drpub\": here(\"data\", \"raw\", \"public\", \"spielman\", \"input\"),\n",
    "    \"drpub2\": here(\"data\", \"raw\", \"public\"),\n",
    "    \"drpriv\": here(\"data\", \"raw\", \"private\"),\n",
    "    \"ddpub\": here(\"data\", \"derived\", \"public\", \"version1\"),\n",
    "    \"ddpriv\": here(\"data\", \"derived\", \"private\"),\n",
    "    \"rfig\": here(\"results\", \"figures\"),\n",
    "    \"roth\": here(\"results\", \"other\"),\n",
    "    \"rtab\": here(\"results\", \"tables\"),\n",
    "    \"og_out\": here(\"data\", \"raw\", \"public\", \"spielman\", \"output\"),\n",
    "    \"dmet\": here(\"data\", \"metadata\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84769898-6733-4f30-a7e6-9ac384edd57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Switch from False to True to regenerate documentation of computational environment\n",
    "# Note that this approach is not perfect -- it may miss some packages\n",
    "# This code may work better from the command prompt\n",
    "if False:\n",
    "    !pip install pigar\n",
    "    !pigar generate -f ../environment/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0da483-07cc-494a-aa07-5896779b0a37",
   "metadata": {},
   "source": [
    "### Data and variables\n",
    "\n",
    "For Spielman et al.'s original study, the data sources were the 2008-2012 5-year American Community Survey and the 2010 decennial census.\n",
    "Spielman et al. downloaded their data from Social Explorer; in our reproduction, we pull our data directly from the census into Python via a census API package known as pygris.\n",
    "These variables are based on the original work by Cutter et al. to create SoVI, and cover a wide range of social and demographic information, the particulars of which are described below.\n",
    "\n",
    "In order to confirm that our data and Spielman et al.'s data perfectly match each other, we import the names of relevant variables from both datasets here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddd1b7-75ff-4dd5-8f76-4b5d51dcf6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import data dictionary\n",
    "acs_vars = pd.read_csv( here(\"data\", \"metadata\", \"ACS_2012_data_dictionary.csv\") )\n",
    "acs_vars.drop(columns=acs_vars.columns[0], axis=1, inplace=True)\n",
    "\n",
    "acs_variables = list(acs_vars['Reproduction Label'][1:])\n",
    "spielman_acs_variables = list(acs_vars['Spielman Label'][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb97cb-7411-4ea7-8cc2-17e2008580f3",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### (1) 2008-2012 American Community Survey (5-year)\n",
    "Used in both original study and reproduction.\n",
    "\n",
    "**Planned deviation:** to enhance reproducibility, we draw the data directly from the census into python using the pygris package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283623f-7412-4c0c-a981-93884617aa73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Switch from False to True to download fresh data from the Census\n",
    "if False:\n",
    "    # Acquire attribute data for reproduction \n",
    "    counties_detailed = get_census(dataset = \"acs/acs5\", # dataset name on the Census API you are connecting to; find datasets at https://api.census.gov/data.html\n",
    "                            variables = acs_variables, # string (or list of strings) of desired vars. For the 2021 5-year ACS Data Profile, those variable IDs are found at https://api.census.gov/data/2021/acs/acs5/profile/variables.html\n",
    "                            year = 2012, # year of your data (or end-year for a 5-year ACS sample)\n",
    "                            params = { # dict of query parameters to send to the API.\n",
    "                              \"for\": \"county:*\"},\n",
    "                            guess_dtypes = True,\n",
    "                            return_geoid = True)\n",
    "\n",
    "    # Drop Puerto Rico\n",
    "    counties_detailed = counties_detailed.loc[~counties_detailed['GEOID'].str.startswith('72')]\n",
    "\n",
    "    # Download and save raw data\n",
    "    counties_detailed.to_csv( here(path[\"drpub2\"], \"counties_attributes_raw.csv\"))\n",
    "else:\n",
    "    counties_detailed = pd.read_csv( here(path[\"drpub2\"], \"counties_attributes_raw.csv\"), dtype = {'GEOID': object} )\n",
    "    counties_detailed = counties_detailed.drop(counties_detailed.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0877e17-47dd-4c31-99c2-e22990e9d34a",
   "metadata": {},
   "source": [
    "Load data from Spielman et al.'s research repository for validation of the reproduction study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152b5a9-cacb-447f-80f6-597398c0d655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import original data from Spielman et al.\n",
    "\n",
    "# Import base ACS data\n",
    "make_strings = {'Geo_FIPS': object, 'Geo_STATE': object, 'Geo_COUNTY': object,\n",
    "                'Geo_TRACT': object, 'Geo_CBSA': object, 'Geo_CSA': object}\n",
    "\n",
    "acs = pd.read_csv(here(path[\"drpub\"], 'sovi_acs.csv'),\n",
    "                  dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "\n",
    "# Import, join an ACS supplemental\n",
    "acs_sup2 = pd.read_csv(here(path[\"drpub\"], 'sovi_acs_kids.csv'),\n",
    "                           dtype=make_strings, skiprows=1,encoding='latin-1')\n",
    "\n",
    "acs = acs.merge(acs_sup2, how = \"inner\", on='Geo_FIPS')\n",
    "\n",
    "# Drop Puerto Rico\n",
    "acs = acs[acs.Geo_STATE_x != '72'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c3c905-1571-448a-92e1-e609cebc745b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Markdown( here(path[\"dmet\"], \"ACS_2012_geographic_metadata.md\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db055c9-0130-4508-8139-55fda362cb80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acs_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba60fbe4-94ad-46f8-9401-7182992d669a",
   "metadata": {},
   "source": [
    "The above are the metadata files that we wrote for our pygris-acquired version of this data, stored as ACS_2012_data_dictionary.csv and ACS_2012_geographic_metadata.md. \n",
    "The metadata files provided by Spielman et al. are also in our repository, named sovi_acs.txt and sovi_acs_kids.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb64c5f-753d-4400-aa27-84020ab5ab64",
   "metadata": {},
   "source": [
    "#### (2) 2010 Decennial Census\n",
    "Used in Spielman et al.'s original study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a3b73-07db-4c92-9eff-59e7a4168701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import decennial supplemental\n",
    "dec_sup1 = pd.read_csv(here(path[\"drpub\"],'sovi_decennial_sup1.csv'),\n",
    "        dtype=make_strings,skiprows=1,encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eece61-5e76-402a-9ccf-006cea0101df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Markdown( here(path[\"dmet\"], \"dec_2010_metadata.md\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4848b82-b8f4-4b4f-b33d-5027e3cdb96c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Original metadata file provided by Spielman et al. as sovi_decennial_sup1.txt.\n",
    "\n",
    "#### (3) USA Counties Shapefile\n",
    "Used in Spielman et al.'s original study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98aa9a5-28f0-45b1-a0fe-ca0eb9fa721f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spielman_geom = gpd.read_file( here(path[\"drpub\"], \"USA_Counties_500k.shp\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c760a-1c31-47c2-acaa-b8689392bd24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Markdown( here(path[\"dmet\"], 'USA_counties_metadata.md') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e39487-bdcd-4bc1-8f10-1b02cf2af4c1",
   "metadata": {},
   "source": [
    "No original metadata file provided.\n",
    "\n",
    "#### (4) USA Counties Cartographic Boundaries\n",
    "\n",
    "Used in reproduction study.\n",
    "\n",
    "**Planned deviation:** to enhance reproducibility, we draw the data directly from the census into python using the pygris package. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dfa8d7-a08e-4411-8c37-855d0b18d170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Switch False to True if you wish to acquire data directly from census\n",
    "if False:\n",
    "    # Acquire geographical data for reproduction\n",
    "    counties_shp = counties(cb = True, year = 2010, cache = True) # year 2012 (and 2011) cartographic boundaries not available\n",
    "\n",
    "    # Save raw data\n",
    "    counties_shp.to_file( here(path[\"drpub2\"], \"counties_geometries_raw.gpkg\") )\n",
    "else:\n",
    "    counties_shp = gpd.read_file( here(path[\"drpub2\"], \"counties_geometries_raw.gpkg\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28364df-eabd-46eb-aa2f-b9b95dfad9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Markdown( here(path[\"dmet\"], \"county_geom_2010_metadata.md\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340f287-0381-499a-be9c-67ccd590edfd",
   "metadata": {},
   "source": [
    "The metadata file for this data is stored as county_geom_2010_metadata.md."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02df98-648b-4350-9d6d-9e67fb62906e",
   "metadata": {},
   "source": [
    "### Data transformations\n",
    "A workflow diagram for this section is displayed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13988a56-258a-4bfa-96c5-529f0eea4c07",
   "metadata": {},
   "source": [
    "![Data Preparation Workflow](../../results/figures/workflow_data_transformations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab958819-38ce-43f3-ac73-f6bc3662ad24",
   "metadata": {},
   "source": [
    "We begin with step P1: joining the geometry and attribute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52589e-1758-43f7-b5df-ac7544dbc567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step P1\n",
    "# Join geometry and attribute data for reproduction \n",
    "counties_shp['GEOID'] = counties_shp.STATE + counties_shp.COUNTY\n",
    "counties = counties_shp.merge(counties_detailed, how = \"inner\", on = \"GEOID\")\n",
    "\n",
    "# Also join Spielman's land area information to the rest of Spielman's data\n",
    "# (to check that all data is accurate, not for purposes of analysis)\n",
    "acs = acs.merge(dec_sup1, how = \"inner\", on='Geo_FIPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32deeaf1-fb2a-40a8-8f32-d8165a668f9c",
   "metadata": {},
   "source": [
    "**Planned deviation:** Because we decided to acquire our data independently from Spielman et al., we need to check that our data is indeed the same as theirs.\n",
    "\n",
    "To begin, we define a function that can check that the entries of two pandas DataFrames are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16709b92-5656-4319-b3dc-6e4add5de861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function that can determine whether every entry in specified columns of two tables match  \n",
    "def equiv(table1, sort1, column1, table2, sort2, column2):\n",
    "    ''' \n",
    "    Tests two tables to see whether corresponding columns have equivalent entries.\n",
    "    \n",
    "    Parameters:\n",
    "    table1 - the first table\n",
    "    sort1 - the column in the first table to join by (str)\n",
    "    column1 - the column(s) in the first table to test the values of (list of str) (should list analogous columns for columns2) \n",
    "    table2 - the second table\n",
    "    sort2 - the column in the second table to join by (str)\n",
    "    column2 - the column(s) in the second table to test the values of (list of str)\n",
    "    '''\n",
    "    # Sort tables\n",
    "    table1 = table1.sort_values(by = sort1).reset_index()\n",
    "    table2 = table2.sort_values(by = sort2).reset_index()\n",
    "    \n",
    "    # Rename column name in table2 to match that in table1\n",
    "    for i in range(len(column1)):\n",
    "        table2 = table2.rename(columns={column2[i]: column1[i]})\n",
    "\n",
    "    # Select the columns to test equivalency of\n",
    "    table1 = table1[column1]\n",
    "    table2 = table2[column1]\n",
    "    \n",
    "    # Perform equivalency test\n",
    "    test = table1.eq(table2)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e627ae1-bf8d-4d3c-867a-2fb55c39cec2",
   "metadata": {},
   "source": [
    "Next, we round our area columns to the nearest integer, just for the purposes of comparing the two columns. These columns came from different sources and we know that they do not match up exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b63cc6f-6e08-4cd6-9a65-7478b24bd763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Round area column\n",
    "# acs['SE_T02A_002_check'] = acs.SE_T02A_002.round(0)\n",
    "# counties['CENSUSAREA_check'] = counties.CENSUSAREA.round(0)\n",
    "\n",
    "# Add the area variables to the lists of variables\n",
    "acs_variables.append('CENSUSAREA')\n",
    "spielman_acs_variables.append('SE_T02A_002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb216f-fa73-4cc8-9508-b49ebae49e40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform equivalency test\n",
    "test = equiv(counties, \"GEOID\", acs_variables, acs, \"Geo_FIPS\", spielman_acs_variables)\n",
    "matching_cols = pd.DataFrame({\"test\": test.sum().eq(3143)}) # 3143 matches the number of rows \n",
    "matching_cols.loc[~matching_cols.test] # Identify the columns that have some data discrepencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d1418-7187-4f97-82dd-180fa118d185",
   "metadata": {},
   "source": [
    "The following variables have some discrepancy between the original and reproduction data:\n",
    "- B25077_001E\n",
    "- CENSUSAREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0490293-126a-4052-b089-518129bd03ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect the data values for B25077_001E at the indices with data discrepancies\n",
    "\n",
    "# Find the rows for which there are data discrepancies\n",
    "messed_up_indices = test[[\"B25077_001E\"]].loc[~test.B25077_001E]\n",
    "\n",
    "# Select the data of interest from tygris\n",
    "tygris_data = counties.sort_values(by = \"GEOID\")\\\n",
    "    .reset_index().loc[messed_up_indices.index]\\\n",
    "    [[\"GEOID\", \"B25077_001E\"]]\n",
    "\n",
    "# Select the data of interest from Spielman et al.\n",
    "spielman_data = acs.sort_values(by = \"Geo_FIPS\")\\\n",
    "    .reset_index().loc[messed_up_indices.index]\\\n",
    "    [[\"Geo_FIPS\", \"ACS12_5yr_B25077001\"]]\n",
    "\n",
    "# Join and inspect\n",
    "merged = tygris_data.merge(spielman_data, how = \"inner\", left_on = \"GEOID\", right_on = \"Geo_FIPS\")\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0ddbbd-93c9-4221-b84f-9bc795db1ee6",
   "metadata": {},
   "source": [
    "By inspection, we see that the one disagreement between B25077_001E and ACS12_5yr_B25077001 occurs because of a NaN value in an analogous location in each of the two datasets. \n",
    "Rather than revealing an issue in matching our data, this shows us that we will need to impute a missing value for one NaN in B25077_001E -- median home value (see P3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91406dcb-fba5-4176-b16c-ff0eb8a643e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect the data values for CENSUSAREA at the indices with data discrepancies\n",
    "\n",
    "# Find the rows for which there are data discrepancies\n",
    "messed_up_indices = test[[\"CENSUSAREA\"]].loc[~test.CENSUSAREA]\n",
    "\n",
    "# Select the data of interest from tygris\n",
    "tygris_data = counties.sort_values(by = \"GEOID\")\\\n",
    "    .reset_index().loc[messed_up_indices.index]\\\n",
    "    [[\"GEOID\", \"CENSUSAREA\"]]\n",
    "\n",
    "# Select the data of interest from Spielman et al.\n",
    "spielman_data = acs.sort_values(by = \"Geo_FIPS\")\\\n",
    "    .reset_index().loc[messed_up_indices.index]\\\n",
    "    [[\"Geo_FIPS\", \"SE_T02A_002\"]]\n",
    "\n",
    "# Join and inspect\n",
    "merged = tygris_data.merge(spielman_data, how = \"inner\", left_on = \"GEOID\", right_on = \"Geo_FIPS\")\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4dc08b-e781-4253-b655-0464a84c818b",
   "metadata": {},
   "source": [
    "There are many disagreements between CENSUSAREA and SE_T02A_002, but they appear to be relatively minor differences. Let us evaluate how large those differences are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb330bb-7720-4ef2-b1d6-cc4b08c73a91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged[\"Difference\"] = abs(merged[\"CENSUSAREA\"] - merged[\"SE_T02A_002\"])\n",
    "print(\"Maximum difference:\", merged['Difference'].max(), \"\\nAverage difference:\", merged['Difference'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3485a9e1-cb07-49ce-842b-ad47424d1ab2",
   "metadata": {},
   "source": [
    "The largest discrepency between the two different sources of land area data is just over 0.01 square miles and the average difference (amongst those with a difference) is tiny. With such a minor difference between our data and theirs, for our purposes we will consider our data roughly the same as Spielman et al.'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53402be-c51e-422b-917b-a49af9d9c568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step P2\n",
    "# Calculating the variables used in SoVI\n",
    "counties['MEDAGE_ACS'] = counties.B01002_001E\n",
    "counties['BLACK_ACS'] = counties.B03002_004E / (counties.B03002_001E)\n",
    "counties['QNATAM_ACS'] = counties.B03002_005E / (counties.B03002_001E)\n",
    "counties['QASIAN_ACS'] = counties.B03002_006E / (counties.B03002_001E)\n",
    "counties['QHISP_ACS'] = counties.B03002_012E / (counties.B03002_001E)\n",
    "counties['QAGEDEP_ACS'] = (counties.B06001_002E + counties.B09020_001E) / (counties.B01003_001E)\n",
    "counties['QPUNIT_ACS'] = counties.B25008_001E / (counties.B25002_002E)\n",
    "counties['PRENTER_ACS'] = counties.B25003_003E / (counties.B25002_001E)\n",
    "counties['QNRRES_ACS'] = counties.B09020_021E / (counties.B01003_001E)\n",
    "counties['QFEMALE_ACS'] = counties.B01001_026E / (counties.B01003_001E)\n",
    "counties['QFHH_ACS'] = counties.B11001_006E / (counties.B11001_001E)\n",
    "counties['QUNOCCHU_ACS'] = counties.B25002_003E / (counties.B25002_001E)\n",
    "counties['QCVLUN'] = (counties.B23022_025E + counties.B23022_049E) / \\\n",
    "                counties.B23022_001E\n",
    "counties['QPOVTY'] = (counties.B17021_002E) / counties.B17021_001E\n",
    "counties['QMOHO'] = (counties.B25024_010E) / counties.B25024_001E\n",
    "counties['QFEMLBR'] = (counties.C24010_038E) / counties.C24010_001E\n",
    "counties['QSSBEN'] = (counties.B19055_002E) / counties.B19055_001E\n",
    "counties['QFAM'] = (counties.B09002_002E) / counties.B09002_001E\n",
    "counties['QRICH200K'] = (counties.B19001_017E) / counties.B11001_001E\n",
    "counties['PERCAP_ALT'] = counties.B19025_001E / (counties.B25008_001E)\n",
    "counties['QESL_ALT'] = (counties.B06007_005E + counties.B06007_008E) / \\\n",
    "                  counties.B06007_001E\n",
    "counties['QED12LES_ALT'] = (counties.B16010_002E) / counties.B16010_001E \n",
    "counties['QEXTRCT_ALT'] = (counties.C24050_002E) / counties.C24050_001E \n",
    "counties['QSERV_ALT'] = (counties.C24050_029E) / counties.C24050_001E \n",
    "counties['QNOAUTO_ALT'] = (counties.B08201_002E) / counties.B08201_001E \n",
    "counties['MDGRENT_ALT'] = counties.B25064_001E \n",
    "counties['MHSEVAL_ALT'] = counties.B25077_001E \n",
    "counties['POPDENS'] = counties.B01003_001E / (counties.CENSUSAREA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab95227-ba96-4298-bb8a-2e60bfb07d09",
   "metadata": {},
   "source": [
    "As noted before, B25077_001E is missing a data value.\n",
    "We now perform one final check to see if we need to impute anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f0061-ed35-43dc-9617-7a18dc7136c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "for i in counties.columns:\n",
    "    x = counties[i].isnull().sum()\n",
    "    if x > 0:\n",
    "        print(i, \"contains\", x, \"missing value(s).\")\n",
    "        \n",
    "# Check for infinities\n",
    "counties_num = counties.select_dtypes(include=['int64','float64'])\n",
    "for i in counties_num.columns:\n",
    "    xmin = counties_num[i].min()\n",
    "    xmax = counties_num[i].max()\n",
    "    if xmin == -np.inf:\n",
    "        print(i, \"contains a negative infinity\")\n",
    "    elif xmax == np.inf:\n",
    "        print(i, \"contains a positive infinity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57592b5-e7f0-4e87-8dd5-2ac0de94665d",
   "metadata": {},
   "source": [
    "There are four variables with missing data. LSAD is not used in our analysis, so we may ignore this. B25077_001E and MHSEVAL_ALT are literally identical, so we will ignore B25077_001E and simply impute for MHSEVAL_ALT's one missing value. We also need to impute for QFAM's 2 missing values. We use the same imputation decisions that Spielman et al. employ in their analysis.\n",
    "\n",
    "**Unplanned deviation:** When imputing for MHSEVAL_ALT's missing data, we removed a fair amount of extraneous code that was filling in missing spatial lag data with original data for the county. This was unnecessary because we only needed to impute data for one county and that county had spatial lag data. Also note that Spielman et al.'s method for imputing data for MHSEVAL_ALT is a deviation from Cutter's original methodology, in which she imputed a 0 for any missing value. While this is a deviation from the original SoVI methodology, 0 is an unrealistic median home value, so Spielman et al.'s method for imputation seems like a reasonable improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f54e762-4899-4330-99a5-eeffb246755c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step P3\n",
    "# Replace missing QFAM data with 0\n",
    "counties.QFAM = counties.QFAM.replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "# Replace missing MHSEVAL_ALT data with its spatial lag\n",
    "\n",
    "# Calculate spatial weights matrix\n",
    "w = lps.weights.Queen.from_dataframe(counties) \n",
    "w.transform = 'R'\n",
    "# Calculate spatial lag\n",
    "counties['MHSEVAL_ALT_LAG'] = lps.weights.lag_spatial(w, counties.MHSEVAL_ALT)\n",
    "# Impute for the missing value\n",
    "counties.MHSEVAL_ALT[np.isnan(counties['MHSEVAL_ALT'])] = counties[[\"MHSEVAL_ALT_LAG\"]][pd.isna(counties['MHSEVAL_ALT'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b868c-9a1c-465e-be0b-1275d292ada9",
   "metadata": {},
   "source": [
    "The missing data procedure attempts to fill some counties' missing data with the average values of the surrounding counties.\n",
    "This procedure produces a warning about 10 disconnected components and 7 islands in the weights matrix.\n",
    "The cause of this error is areas of the United States that are not contiguous with one another.\n",
    "Fortunately, these areas are not missing any data, and therefore this error does not affect our procedure to fill gaps in missing data.\n",
    "\n",
    "Before adjusting directionality, let us check that all of our derived variables match all of Spielman et al.'s derived variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be79dfe4-ed76-4113-858f-feb85d819d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import Spielman et al.'s derived variables\n",
    "US_All = pd.read_csv(here(\"data\", \"raw\", \"public\", \"spielman\", \"output\", \"sovi_inputs.csv\"))\n",
    "counties.to_csv(here(path[\"ddpub\"],'counties.csv'))  \n",
    "counties.to_file(here(path[\"ddpub\"],'counties.gpkg'))  \n",
    "counties = pd.read_csv(here(path[\"ddpub\"], \"counties.csv\"), dtype = {'GEOID': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f616b-a51f-4a00-8d50-ba74dffb0873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the relevant columns\n",
    "\n",
    "# Attribute name and expected influence on vulnerability\n",
    "input_names = [['MEDAGE_ACS', 'pos', 'person', 'Median Age'],\n",
    "               ['BLACK_ACS', 'pos', 'person', 'Pop African-American (%)'],\n",
    "               ['QNATAM_ACS', 'pos', 'person', 'Pop Native American (%)'],\n",
    "               ['QASIAN_ACS', 'pos', 'person', 'Pop Asian (%)'],\n",
    "               ['QHISP_ACS', 'pos', 'person', 'Pop Hispanic (%)'],\n",
    "               ['QAGEDEP_ACS', 'pos', 'person', 'Age Dependency (%)'],\n",
    "               ['QPUNIT_ACS', 'pos', 'person', 'Persons Per Housing Unit'],\n",
    "               ['PRENTER_ACS', 'pos', 'hu', 'Rental Housing (%)'],\n",
    "               ['QNRRES_ACS', 'pos', 'person', 'Nursing Home Residents (%)'],\n",
    "               ['QFEMALE_ACS', 'pos', 'person', 'Pop Female (%)'],\n",
    "               ['QFHH_ACS', 'pos', 'hu', 'Female-Headed Households (%)'],\n",
    "               ['QUNOCCHU_ACS', 'pos', 'hu', 'Vacant Housing (%)'],\n",
    "               ['PERCAP_ALT', 'neg', 'person', 'Per-Capita Income'],\n",
    "               ['QESL_ALT', 'pos', 'person', 'English as Second Language (%)'],\n",
    "               ['QCVLUN', 'pos', 'person', 'Unemployment (%)'],\n",
    "               ['QPOVTY', 'pos', 'person', 'Poverty (%)'],\n",
    "               ['QMOHO', 'pos', 'hu', 'Mobile Homes (%)'],\n",
    "               ['QED12LES_ALT', 'pos', 'person',\n",
    "                   'Adults Completed <Grade 12 (%)'],\n",
    "               ['QFEMLBR', 'pos', 'person', 'Female Employment (%)'],\n",
    "               ['QEXTRCT_ALT', 'pos', 'person',\n",
    "                   'Extractive Sector Employment (%)'],\n",
    "               ['QSERV_ALT', 'pos', 'person', 'Service Sector Employment (%)'],\n",
    "               ['QSSBEN', 'pos', 'hu', 'Social Security Income (%)'],\n",
    "               ['QNOAUTO_ALT', 'pos', 'hu', 'No Automobile (%)'],\n",
    "               ['QFAM', 'neg', 'person', 'Children in Married Families (%)'],\n",
    "               ['QRICH200K', 'neg', 'hu', 'Annual Income >$200K (%)'],\n",
    "               ['MDGRENT_ALT', 'neg', 'hu', 'Median Rent'],\n",
    "               ['MHSEVAL_ALT', 'neg', 'hu', 'Median Home Value'],\n",
    "               ['POPDENS', 'pos', 'person', 'Population Density']]\n",
    "\n",
    "# Get attribute names\n",
    "attr_names1 = [j[0] for j in input_names] + ['GEOID']\n",
    "attr_names2 = [j[0] for j in input_names] + ['Geo_FIPS']\n",
    "\n",
    "# Select only the columns needed to compute SoVI\n",
    "counties = counties[attr_names1]\n",
    "US_All = US_All[attr_names2]\n",
    "\n",
    "counties[\"GEOID\"] = \"g\" + counties[\"GEOID\"]\n",
    "counties['stateID'] = counties.GEOID.str.slice(0, 3, 1)\n",
    "attr_names1.remove('GEOID')\n",
    "counties = counties.set_index(counties[\"GEOID\"]).sort_index()\n",
    "\n",
    "US_All['stateID'] = US_All.Geo_FIPS.str.slice(0, 3, 1)\n",
    "attr_names2.remove('Geo_FIPS')\n",
    "US_All = US_All.set_index(US_All[\"Geo_FIPS\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9050a601-a856-4663-94ef-2c0bafe0d0e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counties.eq(US_All).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa439b5-7e60-48a6-9a3c-a90f400fb6ce",
   "metadata": {},
   "source": [
    "Therre are 3143 observations in the dataset, so it appears that all variables match up perfectly except POPDENS. POPDENS is the one variable that was derived from the land area, so this was to be expected. Let us confirm that the differences between the two datasets are minor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a511f6-0635-4e8f-a354-f67fb7e788b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = (abs(counties[[\"POPDENS\"]] - US_All[[\"POPDENS\"]]))\n",
    "print(\"Maximum difference:\", diff.max()[0], \"\\nAverage difference:\", diff.mean()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a06b0d-9c1e-442a-85a4-cabe5df733cf",
   "metadata": {},
   "source": [
    "With a maximum difference less than 1 and an average difference less than 0.01, our data is sufficiently close to Spielman et al.'s for our purposes.\n",
    "\n",
    "Now we proceed to step P4, switching the directionality of variables as needed in order to ensure that higher values of a variable are associated with higher levels of vulnerability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e94f49-7ca9-47eb-b3c1-03bbb50198f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step P4\n",
    "# Flip signs as needed to ensure that each variable contributes as expected to the final Sovi\n",
    "for name, sign, sample, hrname in input_names:\n",
    "    if sign == 'neg':\n",
    "        counties[name] = -counties[name].values\n",
    "        print(\"Inverting variable:\", name)\n",
    "    elif sign == 'pos':\n",
    "        pass\n",
    "    else:\n",
    "        print(\"problem in flipping signs\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2aa19-baa0-4f90-9ed3-26375019d6c9",
   "metadata": {},
   "source": [
    "A final step of data transformation will be performed at the beginning of the SoVI model analysis.\n",
    "Each demographic variable will be normalized by calculating its z-score.\n",
    "\n",
    "### Analysis\n",
    "#### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4844792-5872-4240-af81-14f250b4ba45",
   "metadata": {},
   "source": [
    "Spielman et al. constructed a class to conduct SPSS-style PCA with varimax rotation in python and validated their procedure against Cutter et al.'s SPSS workflow used to calculate SoVI.\n",
    "Below I include a workflow diagram that shows, without too much detail, the main operations and important outputs of their SPSS_PCA class. \n",
    "After that, I have included their relevant code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542db85-0392-44c4-894f-421948441ad7",
   "metadata": {},
   "source": [
    "![PCA Workflow](../../results/figures/workflow_PCA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1182438-bf82-4ea1-abcd-a485ac631888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SPSS_PCA:\n",
    "\t'''\n",
    "\tA class that integrates most (all?) of the assumptions SPSS imbeds in their\n",
    "    implimnetation of principal components analysis (PCA), which can be found in\n",
    "    thier GUI under Analyze > Dimension Reduction > Factor. This class is not\n",
    "\tintended to be a full blown recreation of the SPSS Factor Analysis GUI, but\n",
    "\tit does replicate (possibly) the most common use cases. Note that this class\n",
    "\twill not produce exactly the same results as SPSS, probably due to differences\n",
    "\tin how eigenvectors/eigenvalues and/or singular values are computed. However,\n",
    "\tthis class does seem to get all the signs to match, which is not really necessary\n",
    "\tbut kinda nice. Most of the approach came from the official SPSS documentation.\n",
    "\n",
    "\tReferences\n",
    "\t----------\n",
    "\tftp://public.dhe.ibm.com/software/analytics/spss/documentation/statistics/20.0/en/client/Manuals/IBM_SPSS_Statistics_Algorithms.pdf\n",
    "\thttp://spssx-discussion.1045642.n5.nabble.com/Interpretation-of-PCA-td1074350.html\n",
    "\thttp://mdp-toolkit.sourceforge.net/api/mdp.nodes.WhiteningNode-class.html\n",
    "\thttps://github.com/mdp-toolkit/mdp-toolkit/blob/master/mdp/nodes/pca_nodes.py\n",
    "\n",
    "\tParameters\n",
    "\t----------\n",
    "\tinputs:  numpy array\n",
    "\t\t\t n x k numpy array; n observations and k variables on each observation\n",
    "\treduce:  boolean (default=False)\n",
    "\t\t\t If True, then use eigenvalues to determine which factors to keep; all\n",
    "\t\t\t results will be based on just these factors. If False use all factors.\n",
    "\tmin_eig: float (default=1.0)\n",
    "\t\t\t If reduce=True, then keep all factors with an eigenvalue greater than\n",
    "\t\t\t min_eig. SPSS default is 1.0. If reduce=False, then min_eig is ignored.\n",
    "\tvarimax: boolean (default=False)\n",
    "\t\t\t If True, then apply a varimax rotation to the results. If False, then\n",
    "\t\t\t return the unrotated results only.\n",
    "\n",
    "\tAttributes\n",
    "\t----------\n",
    "\tz_inputs:\tnumpy array\n",
    "\t\t\t\tz-scores of the input array.\n",
    "\tcomp_mat:\tnumpy array\n",
    "\t\t\t\tComponent matrix (a.k.a, \"loadings\").\n",
    "\tscores:\t\tnumpy array\n",
    "\t\t\t\tNew uncorrelated vectors associated with each observation.\n",
    "\teigenvals_all:\tnumpy array\n",
    "\t\t\t\tEigenvalues associated with each factor.\n",
    "\teigenvals:\tnumpy array\n",
    "\t\t\t\tSubset of eigenvalues_all reflecting only those that meet the\n",
    "\t\t\t\tcriterion defined by parameters reduce and min_eig.\n",
    "\tweights:    numpy array\n",
    "\t\t\t\tValues applied to the input data (after z-scores) to get the PCA\n",
    "\t\t\t\tscores. \"Component score coefficient matrix\" in SPSS or\n",
    "\t\t\t\t\"projection matrix\" in the MDP library.\n",
    "\tcomms: \t\tnumpy array\n",
    "\t\t\t\tCommunalities\n",
    "\tsum_sq_load: numpy array\n",
    "\t\t\t\t Sum of squared loadings.\n",
    "\tcomp_mat_rot: numpy array or None\n",
    "\t\t\t\t  Component matrix after rotation. Ordered from highest to lowest\n",
    "\t\t\t\t  variance explained based on sum_sq_load_rot. None if varimax=False.\n",
    "\tscores_rot:\tnumpy array or None\n",
    "\t\t\t\tUncorrelated vectors associated with each observation, after\n",
    "\t\t\t\trotation. None if varimax=False.\n",
    "\tweights_rot: numpy array or None\n",
    "\t\t\t\tRotated values applied to the input data (after z-scores) to get\n",
    "\t\t\t\tthe PCA\tscores. None if varimax=False.\n",
    "\tsum_sq_load_rot: numpy array or None\n",
    "\t\t\t\t Sum of squared loadings for rotated results. None if\n",
    "\t\t\t\t varimax=False.\n",
    "\n",
    "\t'''\n",
    "\n",
    "\tdef __init__(self, inputs, reduce=False, min_eig=1.0, varimax=False):\n",
    "        # Step S1\n",
    "\t\tz_inputs = ZSCORE(inputs)  # seems necessary for SPSS \"correlation matrix\" setting (their default)\n",
    "        \n",
    "        # The rest is step S2\n",
    "\t\t# run base SPSS-style PCA to get all eigenvalues\n",
    "\t\tpca_node = MDP.nodes.WhiteningNode()  # settings for the PCA\n",
    "\t\tscores = pca_node.execute(z_inputs)  # base run PCA\n",
    "\t\teigenvalues_all = pca_node.d   # rename PCA results\n",
    "\n",
    "\t\t# run SPSS-style PCA based on user settings\n",
    "\t\tpca_node = MDP.nodes.WhiteningNode(reduce=reduce, var_abs=min_eig)  # settings for the PCA\n",
    "\t\tscores = pca_node.execute(z_inputs)  # run PCA  (these have mean=0, std_dev=1)\n",
    "\t\tweights = pca_node.v  # rename PCA results (these might be a transformation of the eigenvectors)\n",
    "\t\teigenvalues = pca_node.d   # rename PCA results\n",
    "\t\tcomponent_matrix = weights * eigenvalues  # compute the loadings\n",
    "\t\tcomponent_matrix = self._reflect(component_matrix)   # get signs to match SPSS\n",
    "\t\tcommunalities = (component_matrix**2).sum(1)   # compute the communalities\n",
    "\t\tsum_sq_loadings = (component_matrix**2).sum(0) # note that this is the same as eigenvalues\n",
    "\t\tweights_reflected = component_matrix/eigenvalues  # get signs to match SPSS\n",
    "\t\tscores_reflected = np.dot(z_inputs, weights_reflected)  # note that abs(scores)=abs(scores_reflected)\n",
    "\n",
    "\t\tif varimax:\n",
    "\t\t\t# SPSS-style varimax rotation prep\n",
    "\t\t\tc_normalizer = 1. / MDP.numx.sqrt(communalities)  # used to normalize inputs to varimax\n",
    "\t\t\tc_normalizer.shape = (component_matrix.shape[0],1)  # reshape to vectorize normalization\n",
    "\t\t\tcm_normalized = c_normalizer * component_matrix  # normalize component matrix for varimax\n",
    "\n",
    "\t\t\t# varimax rotation\n",
    "\t\t\tcm_normalized_varimax = self._varimax(cm_normalized)  # run varimax\n",
    "\t\t\tc_normalizer2 = MDP.numx.sqrt(communalities)  # used to denormalize varimax output\n",
    "\t\t\tc_normalizer2.shape = (component_matrix.shape[0],1)  # reshape to vectorize denormalization\n",
    "\t\t\tcm_varimax = c_normalizer2 * cm_normalized_varimax  # denormalize varimax output\n",
    "\n",
    "\t\t\t# reorder varimax component matrix\n",
    "\t\t\tsorter = (cm_varimax**2).sum(0)  # base the ordering on sum of squared loadings\n",
    "\t\t\tsorter = zip(sorter.tolist(), range(sorter.shape[0]))  # add index to denote current order\n",
    "\t\t\tsorter = sorted(sorter, key=itemgetter(0), reverse=True)  # sort from largest to smallest\n",
    "\t\t\tsum_sq_loadings_varimax, reorderer = zip(*sorter)  # unzip the sorted list\n",
    "\t\t\tsum_sq_loadings_varimax = np.array(sum_sq_loadings_varimax)  # convert to array\n",
    "\t\t\tcm_varimax = cm_varimax[:,reorderer]  # reorder component matrix\n",
    "\n",
    "\t\t\t# varimax scores\n",
    "\t\t\tcm_varimax_reflected = self._reflect(cm_varimax)  # get signs to match SPSS\n",
    "\t\t\tvarimax_weights = np.dot(cm_varimax_reflected,\n",
    "\t\t\t\t\t\t\t  np.linalg.inv(np.dot(cm_varimax_reflected.T,\n",
    "\t\t\t\t\t\t\t  cm_varimax_reflected))) # CM(CM'CM)^-1\n",
    "\t\t\tscores_varimax = np.dot(z_inputs, varimax_weights)\n",
    "\t\telse:\n",
    "\t\t\tcomp_mat_rot = None\n",
    "\t\t\tscores_rot = None\n",
    "\t\t\tweights_rot = None\n",
    "\n",
    "\t\t# assign output variables\n",
    "\t\tself.z_inputs = z_inputs\n",
    "\t\tself.scores = scores_reflected\n",
    "\t\tself.comp_mat = component_matrix\n",
    "\t\tself.eigenvals_all = eigenvalues_all\n",
    "\t\tself.eigenvals = eigenvalues\n",
    "\t\tself.weights = weights_reflected\n",
    "\t\tself.comms = communalities\n",
    "\t\tself.sum_sq_load = sum_sq_loadings\n",
    "\t\tself.comp_mat_rot = cm_varimax_reflected\n",
    "\t\tself.scores_rot = scores_varimax # PCA scores output\n",
    "\t\tself.weights_rot = varimax_weights # PCA weights output\n",
    "\t\tself.sum_sq_load_rot = sum_sq_loadings_varimax\n",
    "\n",
    "\tdef _reflect(self, cm):\n",
    "\t\t# reflect factors with negative sums; SPSS default\n",
    "\t\tcm = copy.deepcopy(cm)\n",
    "\t\treflector = cm.sum(0)\n",
    "\t\tfor column, measure in enumerate(reflector):\n",
    "\t\t\tif measure < 0:\n",
    "\t\t\t\tcm[:,column] = -cm[:,column]\n",
    "\t\treturn cm\n",
    "\n",
    "\tdef _varimax(self, Phi, gamma = 1.0, q = 100, tol = 1e-6):\n",
    "\t\t# downloaded from http://en.wikipedia.org/wiki/Talk%3aVarimax_rotation\n",
    "\t\t# also here http://stackoverflow.com/questions/17628589/perform-varimax-rotation-in-python-using-numpy\n",
    "\t\tp,k = Phi.shape\n",
    "\t\tR = np.eye(k)\n",
    "\t\td=0\n",
    "\t\tfor i in range(q):\n",
    "\t\t\td_old = d\n",
    "\t\t\tLambda = np.dot(Phi, R)\n",
    "\t\t\tu,s,vh = np.linalg.svd(np.dot(Phi.T,np.asarray(Lambda)**3 - (gamma/p) *\n",
    "\t\t\t\t\t\t\tnp.dot(Lambda, np.diag(np.diag(np.dot(Lambda.T,Lambda))))))\n",
    "\t\t\tR = np.dot(u,vh)\n",
    "\t\t\td = np.sum(s)\n",
    "\t\t\tif d_old!=0 and d/d_old < 1 + tol:\n",
    "\t\t\t\tbreak\n",
    "\t\treturn np.dot(Phi, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10f795-7c15-4ac7-abd5-207b72968706",
   "metadata": {},
   "source": [
    "#### Basic set-up for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb063798-04fc-43b4-9b97-7b1d14384d94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build FEMA subRegions Dict values= state ID's\n",
    "FEMA_subs = dict()\n",
    "FEMA_subs['FEMA_1'] = ['g23g33g25', 'g50', 'g09', 'g44']\n",
    "FEMA_subs['FEMA_2'] = ['g36', 'g34']\n",
    "FEMA_subs['FEMA_3'] = ['g42', 'g10', 'g11', 'g24', 'g51', 'g54']\n",
    "FEMA_subs['FEMA_4'] = ['g21', 'g47', 'g37', 'g28', 'g01', 'g13', 'g45', 'g12']\n",
    "FEMA_subs['FEMA_5'] = ['g27', 'g55', 'g26', 'g17', 'g18', 'g39']\n",
    "FEMA_subs['FEMA_6'] = ['g35', 'g48', 'g40', 'g05', 'g22']\n",
    "FEMA_subs['FEMA_7'] = ['g31', 'g19', 'g20', 'g29']\n",
    "FEMA_subs['FEMA_8'] = ['g30', 'g38', 'g56', 'g46', 'g49', 'g08']\n",
    "FEMA_subs['FEMA_9'] = ['g06', 'g32', 'g04']\n",
    "FEMA_subs['FEMA_10'] = ['g53', 'g41', 'g16']\n",
    "\n",
    "####################################\n",
    "# DataFrames to hold US, FEMA region, and state level results\n",
    "####################################\n",
    "\n",
    "# Dict to hold variable loadings\n",
    "# key will be [USA, Fema_region, stateid] depending on level of analysis\n",
    "varContrib = {}\n",
    "\n",
    "# National Score\n",
    "US_Sovi_Score = pd.DataFrame(index=counties.GEOID,\n",
    "                             columns=['sovi', 'rank'])\n",
    "\n",
    "# In the FEMA_Region_Sovi_Score data frame ranks are BY FEMA REGION.\n",
    "# The data frame holds both the SOVI score and the county rank\n",
    "# This means that there should be 10 counties with rank 1 (one for each\n",
    "# FEMA Region)\n",
    "FEMA_Region_Sovi_Score = pd.DataFrame(index=counties.GEOID,\n",
    "                                      columns=['sovi', 'rank', 'fema_region'])\n",
    "\n",
    "# Create New England conglomerate of states\n",
    "# These are the FIPS codes for the states with the letter \"g\" appended\n",
    "counties.loc[counties.stateID.isin(['g23', 'g33', 'g25']), 'stateID'] = 'g23g33g25'\n",
    "\n",
    "# These are the states in the state level analysis\n",
    "stateList = ['g23g33g25', 'g36', 'g51', 'g13',\n",
    "             'g17', 'g48', 'g29', 'g46', 'g06', 'g16']\n",
    "\n",
    "# In the State_Sovi_Score data frame ranks are BY STATE.\n",
    "# The data frame holds both the SOVI score and the county rank\n",
    "# This means that there should be 10 counties with rank 1 (one for each\n",
    "# state in stateList)\n",
    "State_Sovi_Score = pd.DataFrame(\n",
    "    index=counties.index[counties.stateID.isin(stateList)],\n",
    "    columns=['sovi', 'rank', 'state_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b133f6-632a-4091-bc21-d0c3df5ff21e",
   "metadata": {},
   "source": [
    "#### Calculating SoVI\n",
    "At this stage, we seek to calculate the SoVI ranks and variable weightings on the national, FEMA region, and state-level spatial extents. Below is a workflow for calculating SoVI, followed by the code for each spatial extent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfffdd8-2d0d-4929-9aa7-fbc3737380c1",
   "metadata": {},
   "source": [
    "![National SoVI Workflow](../../results/figures/workflow_SoVI.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d6a547-b9c0-4b15-ba0e-e621db2c1243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "# Compute National SoVI\n",
    "#######################\n",
    "# compute SoVI\n",
    "# Step M2\n",
    "inputData = counties.drop(['GEOID', 'stateID'], axis=1, inplace=False)\n",
    "\n",
    "# Step M3\n",
    "inputData_array = inputData.values  # Convert DataFrame to NumPy array\n",
    "\n",
    "# Step M4\n",
    "pca = SPSS_PCA(inputData_array, reduce=True, varimax=True)\n",
    "\n",
    "# variance explained for each component is the eigenvalue divided by the sum of all eigenvalues\n",
    "# the eigenvalue is equivalent to the sum of squared loadings\n",
    "variance_explained = pca.sum_sq_load_rot / pca.eigenvals_all.sum()\n",
    "print(\"Percent variance explained by each component\")\n",
    "print(variance_explained)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89775b-fe89-40da-b757-18800df80a44",
   "metadata": {},
   "source": [
    "Factor loadings for national model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a5711-08cf-4876-9ed4-4782818d6bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loadings = pd.DataFrame(pca.weights_rot)\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40361ff2-a2f5-4527-9e55-412f83206367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step M5\n",
    "# get calculated Principal Component values from PCA\n",
    "sovi_actual_us = pca.scores_rot\n",
    "\n",
    "# weight both loadings and component values by variance explained\n",
    "for i in range(0, len(variance_explained)):\n",
    "    sovi_actual_us[i] = sovi_actual_us[i] * (variance_explained[i])\n",
    "    loadings[i] = loadings[i] * variance_explained[i]\n",
    "\n",
    "# Step M6\n",
    "sovi_actual_us = pd.DataFrame(\n",
    "    sovi_actual_us, index=counties.GEOID)\n",
    "\n",
    "# sum reweighted components\n",
    "sovi_actual_us['sovi'] = sovi_actual_us.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5149c0a-1830-43c8-bc78-38196e1dd779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step M8\n",
    "sovi_actual_us['rank'] = sovi_actual_us['sovi'].rank(\n",
    "    method='average', ascending=False)\n",
    "US_Sovi_Score.update(sovi_actual_us)\n",
    "\n",
    "# Step M9\n",
    "attrib_contribution_us = loadings.sum(1)\n",
    "varContrib['USA'] = zip(attr_names1, attrib_contribution_us.tolist()) # Generate dictionary for all net loadings by variable for US\n",
    "\n",
    "# Quick check of ranks: max should equal number of counties in US\n",
    "try:\n",
    "    US_Sovi_Score['rank'].max() == len(counties)\n",
    "except:\n",
    "    print(\"error in ranking check\")\n",
    "    raise\n",
    "\n",
    "# cleanup\n",
    "del inputData\n",
    "# del inputData_norm\n",
    "\n",
    "# del sovi_actual_us\n",
    "del attrib_contribution_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f914c9-1c97-4028-baf0-984ed5f02fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "national = pd.DataFrame(pca.scores_rot)\n",
    "national"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988115b-20fb-4f75-ba31-1b114329dc20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########################\n",
    "# Compute FEMA Region SoVI\n",
    "###########################\n",
    "for i in FEMA_subs:\n",
    "\n",
    "    # Step M1: Subset FEMA subregion\n",
    "    FEMARegionData = counties[counties['stateID'].isin(FEMA_subs[i])]\n",
    "\n",
    "    # Step M2\n",
    "    inputData = FEMARegionData.drop(\n",
    "        ['GEOID', 'stateID'], axis=1, inplace=False)\n",
    "    \n",
    "    # Step M3\n",
    "    inputData_array = inputData.values  # Convert DataFrame to NumPy array\n",
    "    \n",
    "    # Step M4\n",
    "    pca = SPSS_PCA(inputData_array, reduce=True, varimax=True)\n",
    "    variance_explained = pca.sum_sq_load_rot / pca.eigenvals_all.sum()\n",
    "    loadings = pd.DataFrame(pca.weights_rot)\n",
    "    \n",
    "    # Step M5\n",
    "    sovi_actual_fema = pca.scores_rot\n",
    "\n",
    "    # weight both loadings and component values by variance explained\n",
    "    for c in range(0, len(variance_explained)):\n",
    "        sovi_actual_fema[c] = sovi_actual_fema[c] * (variance_explained[c])\n",
    "        loadings[c] = loadings[c] * variance_explained[c]\n",
    "    \n",
    "    # Step M6\n",
    "    sovi_actual_fema = pd.DataFrame(\n",
    "        sovi_actual_fema, index=FEMARegionData.index)\n",
    "\n",
    "    # sum reweighted components\n",
    "    sovi_actual_fema['sovi'] = sovi_actual_fema.sum(axis=1) \n",
    "\n",
    "    # Step M7\n",
    "    sovi_actual_fema['fema_region'] = i\n",
    "    \n",
    "    # Step M8\n",
    "    sovi_actual_fema['rank'] = sovi_actual_fema['sovi'].rank(\n",
    "        method='average', ascending=False)\n",
    "    FEMA_Region_Sovi_Score.update(sovi_actual_fema)\n",
    "    \n",
    "    # Step M9\n",
    "    attrib_contribution_fema = loadings.sum(1)\n",
    "    varContrib[i] = zip(attr_names1, attrib_contribution_fema.tolist())\n",
    "\n",
    "# cleanup\n",
    "del FEMARegionData\n",
    "del inputData\n",
    "del sovi_actual_fema\n",
    "del attrib_contribution_fema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a464eb-91cc-4956-9751-97e862b368dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# Compute State Level SoVI\n",
    "############################\n",
    "for st in stateList:\n",
    "    \n",
    "    # Step M1: Subset FEMA subregion\n",
    "    stateData = counties[counties.stateID == st]\n",
    "\n",
    "    # Step M2\n",
    "    inputData = stateData.drop(['GEOID', 'stateID'], axis=1, inplace=False)\n",
    "    \n",
    "    # Step M3\n",
    "    inputData_array = inputData.values  # Convert DataFrame to NumPy array\n",
    "    \n",
    "    # Step M4\n",
    "    pca = SPSS_PCA(inputData_array, reduce=True, varimax=True)\n",
    "    variance_explained = pca.sum_sq_load_rot / pca.eigenvals_all.sum()\n",
    "    loadings = pd.DataFrame(pca.weights_rot)\n",
    "\n",
    "    # Step M5\n",
    "    sovi_actual = pca.scores_rot\n",
    "    \n",
    "    # weight both loadings and component values by variance explained\n",
    "    for c in range(0, len(variance_explained)):\n",
    "        sovi_actual[c] = sovi_actual[c] * (variance_explained[c])\n",
    "        loadings[c] = loadings[c] * variance_explained[c]\n",
    "    \n",
    "    # Step M6\n",
    "    sovi_actual = pd.DataFrame(\n",
    "        sovi_actual, index=stateData.index)\n",
    "    \n",
    "    # sum reweighted components\n",
    "    sovi_actual['sovi'] = sovi_actual.sum(axis=1) \n",
    "    \n",
    "    # Step M7\n",
    "    sovi_actual['state_id'] = st\n",
    "    \n",
    "    # Step M8\n",
    "    sovi_actual['rank'] = sovi_actual['sovi'].rank(\n",
    "        method='average', ascending=False)\n",
    "    State_Sovi_Score.update(sovi_actual)\n",
    "    \n",
    "    # Step M9\n",
    "    attrib_contribution = pca.weights_rot.sum(1)\n",
    "    varContrib[st] = zip(attr_names1, attrib_contribution.tolist())\n",
    "\n",
    "# cleanup\n",
    "del stateData\n",
    "del inputData\n",
    "del sovi_actual\n",
    "del attrib_contribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb65294-7d26-4764-aa0b-1a1782cafca8",
   "metadata": {},
   "source": [
    "#### Internal consistency analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d245e-b2af-4e37-8540-613ed8a65c0e",
   "metadata": {},
   "source": [
    "Now that we have generated the SoVI scores for the 21 different models, we turn to our analysis of internal consistency.\n",
    "\n",
    "This analysis checks for consistent SoVI rankings of counties in a region of interest (a state or group of small states) through three versions of a SoVI model, each using a different geographic extent for input data. \n",
    "Those extents are: 1) all counties in the country, 2) all the counties in a FEMA region, and 3) all counties in a single state or group of small states.\n",
    "The SoVI scores for the counties in the region of interest are selected and ranked.\n",
    "The agreement between the three sets of rankings is calculated using the Spearman's Rho rank correlation coefficient.\n",
    "If the model is internally consistent, one could expect a nearly perfect positive rank correlation close to 1, implying that counties have similar levels of social vulnerability *vis a vis* one another in the region of interest, regardless of how much extraneous information from other counties in the FEMA region or from the whole United States has been included in the SoVI model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866486e-ecb3-4762-91df-bf0517565ceb",
   "metadata": {},
   "source": [
    "![Internal Consistency Workflow](../../results/figures/workflow_internal_consistency.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1b4cbc-e946-4842-a678-805d969f30d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# Ranks w/ Geographic Extent\n",
    "# For each county rank within state for US, state, and fema_region sovis\n",
    "##########################################################################\n",
    "\n",
    "# Step IC1: Create an empty DataFrame with a column for each SoVI spatial extent and an index of each county FIPS code in the selected state(s) of the 10 FEMA regions\n",
    "county_in_state_rank = pd.DataFrame(index=State_Sovi_Score.index,\n",
    "                                    columns=['state_sovi_rank', 'fema_region_sovi_rank', 'us_sovi_rank'])\n",
    "\n",
    "for st in stateList:\n",
    "    if st == 'g23g33g25':\n",
    "       # Step IC2: Select the index and SoVI scores from national model for Maine, New Hampshire, and Massachusetts\n",
    "        st_cty_scores1 = US_Sovi_Score.loc[['g23' in s for s in US_Sovi_Score.index], 'sovi']\n",
    "        st_cty_scores2 = US_Sovi_Score.loc[['g33' in s for s in US_Sovi_Score.index], 'sovi']\n",
    "        st_cty_scores3 = US_Sovi_Score.loc[['g25' in s for s in US_Sovi_Score.index], 'sovi']\n",
    "        st_cty_scores = pd.concat([st_cty_scores1, st_cty_scores2, st_cty_scores3])\n",
    "\n",
    "        # Step IC3: Re-rank the national SoVI scores but just for the counties in the relevant states\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'us_sovi_rank'] = st_cty_scores.rank(method='average', ascending=False)\n",
    "\n",
    "        # Step IC4: Select the index and SoVI scores from FEMA model for Maine, New Hampshire, and Massachusetts\n",
    "        st_cty_scores1 = FEMA_Region_Sovi_Score.loc[['g23' in s for s in FEMA_Region_Sovi_Score.index], 'sovi']\n",
    "        st_cty_scores2 = FEMA_Region_Sovi_Score.loc[['g33' in s for s in FEMA_Region_Sovi_Score.index], 'sovi']\n",
    "        st_cty_scores3 = FEMA_Region_Sovi_Score.loc[['g25' in s for s in FEMA_Region_Sovi_Score.index], 'sovi']\n",
    "        st_cty_scores = pd.concat([st_cty_scores1, st_cty_scores2, st_cty_scores3])\n",
    "\n",
    "        # Step IC5: Re-rank the FEMA SoVI scores but just for the counties in the relevant states\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'fema_region_sovi_rank'] = st_cty_scores.rank(method='average', ascending=False)\n",
    "\n",
    "        # Step IC6: Pull the state-only SoVI ranks into the same dataframe as the other data\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'state_sovi_rank'] = State_Sovi_Score.loc[State_Sovi_Score['state_id'] == 'g23g33g25', 'rank']\n",
    "\n",
    "    else:\n",
    "        # Step IC2: select the index and SoVI scores from national model for the relevant state\n",
    "        st_cty_scores = US_Sovi_Score.loc[[st in s for s in US_Sovi_Score.index], 'sovi']\n",
    "\n",
    "        # Step IC3: Re-rank the national SoVI scores but just for the counties in the relevant state\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'us_sovi_rank'] = st_cty_scores.rank(method='average', ascending=False)\n",
    "\n",
    "        # Step IC4: Select the index and SoVI scores from FEMA model for the relevant state\n",
    "        st_cty_scores = FEMA_Region_Sovi_Score.loc[[st in s for s in FEMA_Region_Sovi_Score.index], 'sovi']\n",
    "\n",
    "        # Step IC5: Re-rank the FEMA SoVI scores but just for the counties in the relevant state\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'fema_region_sovi_rank'] = st_cty_scores.rank(method='average', ascending=False)\n",
    "\n",
    "        # Step IC6: Pull the state-only SoVI ranks into the same dataframe as the other data\n",
    "        county_in_state_rank.loc[st_cty_scores.index, 'state_sovi_rank'] = State_Sovi_Score.loc[State_Sovi_Score['state_id'] == st, 'rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b6e1c-4a53-436c-9433-e3034a7b4ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# CORRELATIONS\n",
    "######################\n",
    "\n",
    "# Step IC 7: Create an empty DataFrame to hold Spearman test results\n",
    "state_corrs = pd.DataFrame(index = stateList, columns = ['spearman_r_st_fema', 'pvalue_st_fema', 'spearman_r_st_us', 'pvalue_st_us'])\n",
    "\n",
    "for st in stateList:\n",
    "  if st == 'g23g33g25':\n",
    "    # Step IC8: Calculate spearman correlation between state and FEMA, state and national\n",
    "    multi_state_data_tmp1 = county_in_state_rank.loc[['g23' in s for s in county_in_state_rank.index], ]\n",
    "    multi_state_data_tmp2 = county_in_state_rank.loc[['g25' in s for s in county_in_state_rank.index], ]\n",
    "    multi_state_data_tmp3 = county_in_state_rank.loc[['g33' in s for s in county_in_state_rank.index], ]\n",
    "    multi_state_data_tmp = pd.concat([multi_state_data_tmp1, multi_state_data_tmp2, multi_state_data_tmp3])\n",
    "    st_fema_spearman = spearmanr(multi_state_data_tmp[['state_sovi_rank', 'fema_region_sovi_rank']])\n",
    "    st_us_spearman = spearmanr(multi_state_data_tmp[['state_sovi_rank', 'us_sovi_rank']])\n",
    "    state_corrs.loc['g23g33g25', ] = [st_fema_spearman[0], st_fema_spearman[1], st_us_spearman[0], st_us_spearman[1]]\n",
    "  else:\n",
    "    # Step IC8: Calculate spearman correlation between state and FEMA, state and national\n",
    "    st_fema_spearman = spearmanr(county_in_state_rank.loc[[st in s for s in county_in_state_rank.index], ['state_sovi_rank', 'fema_region_sovi_rank']])\n",
    "    st_us_spearman = spearmanr(county_in_state_rank.loc[[st in s for s in county_in_state_rank.index], ['state_sovi_rank', 'us_sovi_rank']])\n",
    "    state_corrs.loc[st, ] = [st_fema_spearman[0], st_fema_spearman[1], st_us_spearman[0], st_us_spearman[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a7d5d-0eb1-4dbc-86a2-fe7550de80b3",
   "metadata": {},
   "source": [
    "#### Theoretical consistency analysis\n",
    "\n",
    "Finally, we investigate the questions surrounding theoretical consistency.\n",
    "\n",
    "This analysis checks for consistent signs and ranks of variables across the same 21 models that were used in the internal consistency analysis.\n",
    "To evaluate the signs and ranks of variables, we sum all components together, producing one vector for each model containing the net effect of each variable on the SoVI score.\n",
    "Theoretical consistency is indicated by little variation amongst all models in the signs and magnitudes of variable weights.\n",
    "Theoretical inconsistency is indicated by substantial variation in the signs and weights of variables and by disagreement between a variable's theoretical influence and modeled influence on vulnerability.\n",
    "\n",
    "**Unplanned deviation:** we were unable to find all of the code for this part the analysis, so we wrote much of this code ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb20f01a-b94c-48b1-8f7a-cd468479057d",
   "metadata": {},
   "source": [
    "![Theoretical Consistency Workflow](../../results/figures/workflow_theoretical_consistency.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d276c-faef-4824-af07-b4bbebf50b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step TC1: Create a DataFrame to hold variable contributions values\n",
    "variable_contributions = pd.DataFrame(index=attr_names1)\n",
    "\n",
    "# Step TC2: Add variable contributions values to DataFrame\n",
    "for area in varContrib.keys():\n",
    "    variable_contributions[area] = [x for i, x in varContrib[area]]\n",
    "    \n",
    "# Step TC3: For all SoVI models, rank variables from the greatest to the least magnitudes\n",
    "rankContrib = abs(variable_contributions).apply(rankdata, axis=0, method='average')\n",
    "rankContrib = (28-rankContrib) + 1\n",
    "\n",
    "# Step TC4: Sort variable rankings according to national model's most to least important\n",
    "rankContrib = rankContrib.sort_values(\"USA\", ascending = True).reset_index()\n",
    "rankContrib.index = rankContrib[\"index\"]\n",
    "rankContrib = rankContrib.drop(columns = [\"index\"])\n",
    "\n",
    "# Step TC5: Calculate summary statistics for each variable\n",
    "summary_stats = pd.DataFrame( {\"Min\": rankContrib.min(axis = 1).round(),\n",
    "                               \"Max\": rankContrib.max(axis = 1).round(),\n",
    "                               \"Range\": rankContrib.max(axis = 1) - rankContrib.min(axis = 1).round(),\n",
    "                               \"Average\": rankContrib.mean(axis = 1).round(2)\n",
    "                              } )\n",
    "\n",
    "# Step TC6: determine signs of USA model\n",
    "def pos_neg(x):\n",
    "    if x > 0:\n",
    "        return \"+\"\n",
    "    else:\n",
    "        return \"-\"\n",
    "usa = variable_contributions[\"USA\"].apply(pos_neg)\n",
    "\n",
    "# Step TC7: Determine all positive/negatives\n",
    "reversals_adj = variable_contributions < 0\n",
    "\n",
    "# Step TC8: Separate data \n",
    "reference = reversals_adj[[\"USA\"]]\n",
    "other_vars = reversals_adj.drop(columns = [\"USA\"])\n",
    "\n",
    "# Step TC9: Determine all reversals from expected sign\n",
    "for i in range(len(other_vars.columns)):\n",
    "    other_vars.iloc[:, i] = reversals_adj[\"USA\"].eq(other_vars.iloc[:, i]).eq(False)\n",
    "    \n",
    "# Step TC10: calculate reversals\n",
    "reversal_sum = pd.DataFrame( {\"Reversals\": other_vars.sum(axis = 1)} )\n",
    "\n",
    "# Step TC11: Join data\n",
    "summary_stats = summary_stats.merge(reversal_sum, left_index = True, right_index = True)\n",
    "\n",
    "# Step TC12: Join data\n",
    "summary_stats = summary_stats.merge(usa, left_index = True, right_index = True)\n",
    "\n",
    "# Step TC13: Change index labels to reflect any changes prior to SoVI calculation\n",
    "for name, sign, sample, hrname in input_names:\n",
    "    if sign == 'neg':\n",
    "        summary_stats = summary_stats.rename(index={name: '- '+ name})\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Table aesthetics edits\n",
    "summary_stats = summary_stats.rename(columns={\"USA\": \"National Model\"})\n",
    "summary_stats = summary_stats.loc[:,['National Model', 'Reversals', 'Min', 'Average', 'Max', 'Range']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f19ca9-595d-45a9-ac98-fe8eee1481f1",
   "metadata": {},
   "source": [
    "We made a different choice than Spielman et al. in this table. Since we adjusted all variables such that larger values are theoretically associated with a higher degree of vulnerability before calculating SoVI, we would expect all outputs to be positive. In Spielman et al.'s \"expected contribution\" column, some signs were negative -- they recorded the directionality we would expect of the variables if they had made no adjustments before calculating SoVI. This leads to a misleading table because their \"original contribution\" column displays the signs of the model output including prior adjustments to directionaity, but the \"expected contribution\" column displays the signs if the model had not adjusted directionality. To make their \"expected contribution\" column consistent with their \"original contribution\" column, they would need all of the signs to be positive in the \"expected contribution\" column. We choose to simply not include an \"expected contribution\" column since there would be no variation within it anyway. Additionally, we add a negative sign in front of any variables that we changed the directionality of for the sake of clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728e8cc-e194-4098-82dd-c04ceeaa7a39",
   "metadata": {},
   "source": [
    "#### Save analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d1cff8-9673-4a50-9258-d8106d68dab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# OUTPUT TABLES\n",
    "#####################################################\n",
    "US_Sovi_Score.to_csv( here(path[\"ddpub\"], 'US_Sovi_Score_Weighted.csv') )\n",
    "\n",
    "# In the FEMA_Region_Sovi_Score data frame ranks are BY FEMA REGION.\n",
    "# The data frame holds both the SOVI score and the county rank\n",
    "# This means that there should be 10 counties with rank 1 (one for each\n",
    "# FEMA Region)\n",
    "FEMA_Region_Sovi_Score.to_csv( here(path[\"ddpub\"], 'FEMA_Region_Sovi_Score_Weighted.csv') )\n",
    "\n",
    "# In the State_Sovi_Score data frame ranks are BY STATE.\n",
    "# The data frame holds both the SOVI score and the county rank\n",
    "# This means that there should be 10 counties with rank 1 (one for each\n",
    "# state in stateList)\n",
    "State_Sovi_Score.to_csv( here(path[\"ddpub\"], 'State_Sovi_Score_Weighted.csv') )\n",
    "\n",
    "# County rank within state for US, state, and fema_region sovis\n",
    "county_in_state_rank.to_csv( here(path[\"ddpub\"], 'County_in_State_Rank_Weighted.csv') )\n",
    "\n",
    "# Variable contributions for sovis at all geographic extents\n",
    "variable_contributions.to_csv( here(path[\"ddpub\"], 'variable_contributions_Weighted.csv') )\n",
    "\n",
    "# Correlation of ranks\n",
    "state_corrs.to_csv( here(path[\"ddpub\"], 'state_fema_us_rank_correlations_Weighted.csv') )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ad915f-d24f-4ee7-ba5f-03b5fc33f346",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6bfd7-cfe7-4649-9e28-f9ce459204c9",
   "metadata": {},
   "source": [
    "### Rpr-H1\n",
    "\n",
    "First, we tested RPr-H1, that reproduced SoVI model scores for each county are not identical to the original study SoVI model scores for each county for each of the 21 SoVI models.\n",
    "\n",
    "We define a function, check_it to check equivalency of the original output files to our reproduced output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec318f0-eaa0-4bf4-868c-7e81a2e25419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_it(file, rounder = False):\n",
    "    '''\n",
    "    Given a file name, this function finds the corresponding file provided by Spielman et al. and the file produced\n",
    "    by our code and returns the number of matches for each column.    \n",
    "    '''\n",
    "    global rpl\n",
    "    global og\n",
    "    global test\n",
    "    \n",
    "    rpl = pd.read_csv( here(path[\"ddpub\"], file) )\n",
    "    og = pd.read_csv( here(path[\"og_out\"], file) )\n",
    "    og = og.rename(columns = {\"Geo_FIPS\": \"GEOID\"})\n",
    "    \n",
    "    if \"sovi\" in rpl.columns:\n",
    "        rpl[\"sovi\"] = rpl[\"sovi\"].round(2)\n",
    "        og[\"sovi\"] = og[\"sovi\"].round(2)\n",
    "    \n",
    "    if \"Unnamed: 0\" in rpl.columns:\n",
    "        rpl.index = rpl[\"Unnamed: 0\"]\n",
    "        rpl = rpl.drop(columns = [\"Unnamed: 0\"])\n",
    "        \n",
    "    if \"Unnamed: 0\" in og.columns:\n",
    "        og.index = og[\"Unnamed: 0\"]\n",
    "        og = og.drop(columns = [\"Unnamed: 0\"])\n",
    "        \n",
    "    if rounder != False:\n",
    "        og = og.round(rounder)\n",
    "        rpl = rpl.round(rounder)\n",
    "        \n",
    "    test = rpl.eq(og)\n",
    "    \n",
    "    if test.sum().eq(len(rpl)).sum() == len(test.sum()):\n",
    "        return print(\"All values match!\")\n",
    "    else:\n",
    "        return test.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9cdf8-2b59-45f1-a2ad-f20337bea7ed",
   "metadata": {},
   "source": [
    "#### US SoVI Scores & Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12fee5-66c5-4433-9ac8-f9cb5c2499b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_it('US_Sovi_Score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4583a-3a1f-4e73-85e3-e0a4f2438cae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged = og.merge(rpl, how = \"inner\", on = \"GEOID\")\n",
    "merged.loc[~test[\"rank\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e57cc-d0f5-4e9d-9303-0d3c9efe6a47",
   "metadata": {},
   "source": [
    "We have identically reproduced national SoVI scores (rounded to 2 decimal points) for all 3143 counties compared to the original study, but two county ranks are different, probably due to the small differences between our area column and theirs. \n",
    "\n",
    "#### FEMA Region SoVI Scores & Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e4e1d-d7d8-492c-b869-5bd0bb228b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_it('FEMA_Region_Sovi_Score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f44e71-b9dc-4638-8b14-97312ffd02de",
   "metadata": {},
   "source": [
    "Our check it function found potential differences in 34 counties.\n",
    "The following table shows the SoVI scores and ranks for those counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7668a46e-fb2d-4a6d-9778-a00f63994be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged = og.merge(rpl, how = \"inner\", on = \"GEOID\")\n",
    "merged.loc[~test[\"rank\"] | ~test[\"sovi\"] | ~test[\"fema_region\"]]#.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2e651-0c5a-44f9-a79e-cedd2ff6a118",
   "metadata": {},
   "source": [
    "These 34 counties are missing data in both the original study and our reproduction study.\n",
    "The counties and county equivalents are all located in Hawaii (FIPS code 15) and Alaska (FIPS code 02).\n",
    "In Spielman et al.'s code, when they define the states in FEMA region IX, they do not include HI, and when they define the states in FEMA region X, they do not include AK. All differences here arise from missing data in analogous places in both my output and theirs. This result was successfully reproduced.\n",
    "\n",
    "#### State SoVI Scores & Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa2fea-026b-4621-a5a2-cc06fc2389a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_it('State_Sovi_Score.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98abad9-8a7a-4e8f-a146-68f704a1f6ed",
   "metadata": {},
   "source": [
    "We have identically reproduced SoVI scores for all state models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d6d80-bb5f-4e55-8807-c4115ed3bb4e",
   "metadata": {},
   "source": [
    "#### County in State Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d004d9c3-e0e4-4569-8f33-13c870b86cd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_it(\"County_in_State_Rank.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ea236-14ca-4242-b70d-c3421d3affb9",
   "metadata": {},
   "source": [
    "We have identically reproduced the SoVI rankings in the state(s) of interest for all 21 models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10082428-a3ac-4dae-8802-95025ab2d229",
   "metadata": {},
   "source": [
    "#### Variable Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301666b-a1c8-412a-854c-10eeabbfaa97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_it(\"variable_contributions.csv\", rounder = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6c3041-58b0-49d8-834d-250fcc128cf0",
   "metadata": {},
   "source": [
    "When rounded to 3 decimal places, we have successfully reproduced all variable contributions for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ae4a3-a948-4f14-8412-621d64875931",
   "metadata": {},
   "source": [
    "#### State FEMA US Rank Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c29b90-1536-4379-88fb-33cda0d6c4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_it(\"state_fema_us_rank_correlations.csv\", rounder = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7902571-4692-49b1-8a36-996193ef1365",
   "metadata": {},
   "source": [
    "When rounded to 14 decimal places, we have succesfully reproduced all Spearman's rank correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378180f4-22f0-4309-aa76-dea07c1ce4ae",
   "metadata": {},
   "source": [
    "### RPr-H2\n",
    "\n",
    "Next, we tested RPr-H2, that reproduced figures and tables for the internal consistency analysis are not identical to the figures and tables of the original study.\n",
    "\n",
    "#### Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe37233-19df-4145-be18-1adf1919034a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read files\n",
    "counties = gpd.read_file( here(path[\"ddpub\"], \"counties.gpkg\") )\n",
    "USA = pd.read_csv( here(path[\"ddpub\"], \"US_Sovi_Score_Weighted.csv\") ).rename( columns={\"sovi\": \"sovi_USA\"} )\n",
    "FEMA = pd.read_csv( here(path[\"ddpub\"], \"FEMA_Region_Sovi_Score_Weighted.csv\") ).rename( columns={\"sovi\": \"sovi_FEMA\"} )\n",
    "CA = pd.read_csv( here(path[\"ddpub\"], \"State_Sovi_Score_Weighted.csv\") ).rename( columns={\"sovi\": \"sovi_CA\"} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d8189f-6653-498d-930c-240ec79dfaf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Edit counties GEOID to match other datasets\n",
    "counties[\"GEOID\"] = \"g\" + counties[\"GEOID\"]\n",
    "\n",
    "# Select just the rows and columns needed\n",
    "counties_CA = counties.loc[counties[\"STATE\"] == \"06\"]\n",
    "counties_CA = counties_CA[[\"GEOID\", \"geometry\"]]\n",
    "\n",
    "# Join all datasets\n",
    "counties_CA = counties_CA.merge(USA, on = \"GEOID\")\n",
    "counties_CA = counties_CA.merge(FEMA, on = \"GEOID\")\n",
    "counties_CA = counties_CA.merge(CA, on = \"GEOID\")\n",
    "\n",
    "counties_CA['rank_USA'] = counties_CA['sovi_USA'].rank(method='average', ascending=False)\n",
    "counties_CA['rank_FEMA'] = counties_CA['sovi_FEMA'].rank(method='average', ascending=False)\n",
    "counties_CA['rank_CA'] = counties_CA['sovi_CA'].rank(method='average', ascending=False)\n",
    "\n",
    "mycolor = ListedColormap('#DBDBDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb32c1-5885-4d10-8939-3d6c804b45e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create overarching plot\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 8))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "ax[2].axis('off')\n",
    "ax[3].axis('off');\n",
    "\n",
    "# Create CA rank map\n",
    "top5_CA = counties_CA.loc[counties_CA[\"rank_CA\"] < 6]\n",
    "bottom5_CA = counties_CA.loc[counties_CA[\"rank_CA\"] > 53]\n",
    "ax[0].set_title(\"(a) California Analysis\")\n",
    "counties_CA.plot(ax = ax[0], cmap = mycolor, edgecolor = 'black', linewidth = .1)\n",
    "top5_CA.plot(ax = ax[0], column = \"rank_CA\", cmap = \"Reds_r\")\n",
    "top5_CA.apply(lambda x: ax[0].text(s=round(x['rank_CA']), color = 'black', x=x.geometry.centroid.coords[0][0], y=x.geometry.centroid.coords[0][1], ha='center', path_effects=[pe.withStroke(linewidth=1.5, foreground=\"white\")]), axis=1, );\n",
    "bottom5_CA.plot(ax = ax[0], column = \"rank_CA\", cmap = \"Blues\");\n",
    "bottom5_CA.apply(lambda x: ax[0].text(s=round(x['rank_CA']), color = 'black', x=x.geometry.centroid.coords[0][0], y=x.geometry.centroid.coords[0][1], ha='center',  path_effects=[pe.withStroke(linewidth=1.5, foreground=\"white\")]), axis=1, );\n",
    "# Create FEMA rank map\n",
    "top5_CA = counties_CA.loc[counties_CA[\"rank_FEMA\"] < 6]\n",
    "bottom5_CA = counties_CA.loc[counties_CA[\"rank_FEMA\"] > 53]\n",
    "ax[1].set_title(\"(b) FEMA Region IX Analysis\")\n",
    "counties_CA.plot(ax = ax[1], cmap = mycolor, edgecolor = 'black', linewidth = .1)\n",
    "top5_CA.plot(ax = ax[1], column = \"rank_FEMA\", cmap = \"Reds_r\")\n",
    "top5_CA.apply(lambda x: ax[1].text(s=round(x['rank_FEMA']), color = 'black', x=x.geometry.centroid.coords[0][0], y=x.geometry.centroid.coords[0][1], ha='center', path_effects=[pe.withStroke(linewidth=1.5, foreground=\"white\")]), axis=1, );\n",
    "bottom5_CA.plot(ax = ax[1], column = \"rank_FEMA\", cmap = \"Blues\");\n",
    "bottom5_CA.apply(lambda x: ax[1].text(s=round(x['rank_FEMA']), color = 'black', x=x.geometry.centroid.coords[0][0], y=x.geometry.centroid.coords[0][1], ha='center',  path_effects=[pe.withStroke(linewidth=1.5, foreground=\"white\")]), axis=1, );\n",
    "# Create USA rank map\n",
    "top5_CA = counties_CA.loc[counties_CA[\"rank_USA\"] < 6]\n",
    "bottom5_CA = counties_CA.loc[counties_CA[\"rank_USA\"] > 53]\n",
    "ax[2].set_title(\"(c) United States Analysis\")\n",
    "counties_CA.plot(ax = ax[2], cmap = mycolor, edgecolor = 'black', linewidth = .1)\n",
    "top5_CA.plot(ax = ax[2], column = \"rank_USA\", cmap = \"Reds_r\")\n",
    "top5_CA.apply(lambda x: ax[2].text(s=round(x['rank_USA']), color = 'black', x=x.geometry.centroid.coords[0][0], y=x.geometry.centroid.coords[0][1], ha='center', path_effects=[pe.withStroke(linewidth=1.5, foreground=\"white\")]), axis=1, );\n",
    "bottom5_CA.plot(ax = ax[2], column = \"rank_USA\", cmap = \"Blues\");\n",
    "bottom5_CA.apply(lambda x: ax[2].text(s=round(x['rank_USA']), color = 'black', x=x.geometry.centroid.coords[0][0], y=x.geometry.centroid.coords[0][1], ha='center',  path_effects=[pe.withStroke(linewidth=1.5, foreground=\"white\")]), axis=1, );\n",
    "# Create range rank map\n",
    "ax[3].set_title(\"(d) Range of SoVI Rankings\")\n",
    "counties_CA[\"min_rank\"] = counties_CA[[\"rank_USA\", \"rank_FEMA\", \"rank_CA\"]].min(axis = 1)\n",
    "counties_CA[\"max_rank\"] = counties_CA[[\"rank_USA\", \"rank_FEMA\", \"rank_CA\"]].max(axis = 1)\n",
    "counties_CA[\"range_rank\"] = counties_CA[\"max_rank\"] - counties_CA[\"min_rank\"]\n",
    "counties_CA.plot(ax = ax[3], column = \"range_rank\", cmap = \"Reds\", edgecolor = 'black', linewidth = .1, scheme=\"User_Defined\", \n",
    "         legend=True, classification_kwds=dict(bins=[5,15,25,35,45]));\n",
    "plt.savefig( here(path[\"rfig\"], 'fig1.png') ) # Save image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f3a5e8-e9a5-4533-9d20-1f36171fbf2c",
   "metadata": {},
   "source": [
    "This figure looks almost the same as Spielman et al.'s. In (a), rank 3 is in a different place; in (b), rank 4 and rank 5 have switched places, but otherwise everything looks good. Our FEMA and state SoVI score data perfectly matched Spielman et al.'s output, so we are not sure what caused these differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34300212-4ee3-47ca-8d8b-06493be2326f",
   "metadata": {},
   "source": [
    "#### Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1610e072-d67b-4932-9055-b9af205ad9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in data\n",
    "table2 = pd.read_csv( here(path[\"ddpub\"], \"state_fema_us_rank_correlations_Weighted.csv\") )\n",
    "\n",
    "# Formatting table\n",
    "table2.index = table2[\"Unnamed: 0\"]\n",
    "table2 = table2.drop(columns = [\"Unnamed: 0\"])\n",
    "table2[\"FEMA Region\"] = [\"I\", \"II\", \"III\", \"IV\", \"V\", \"VI\", \"VII\", \"VIII\", \"IX\", \"X\"]\n",
    "table2[\"All US counties input file versus all counties in a state input file\"] = table2[\"spearman_r_st_us\"].round(2)\n",
    "table2[\"All counties in a FEMA region versus counties in a state within the FEMA region input file\"] = table2[\"spearman_r_st_fema\"].round(2)\n",
    "table2[\"State used for comparison\"] = [\"Composite of ME, NH, MA\", \"NY\", \"VA\", \"GA\", \"IL\", \"TX\", \"MO\", \"SD\", \"CA\", \"ID\"]\n",
    "table2 = table2.transpose().rename_axis('FEMA Region', axis='columns')\n",
    "table2 = table2.rename(columns=table2.iloc[4])\n",
    "table2 = table2.drop(labels = [\"FEMA Region\", \"spearman_r_st_fema\", \"spearman_r_st_us\"], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e8ae66-541e-4534-9800-acc878e750dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (table2.loc[\"pvalue_st_fema\"] < 0.01).sum() == 10 and (table2.loc[\"pvalue_st_us\"] < 0.01).sum() == 10:\n",
    "    table2 = table2.drop([\"pvalue_st_fema\", \"pvalue_st_us\"])\n",
    "    print(\"p < 0.01 for all values\")\n",
    "else:\n",
    "    print(\"Different result than in paper\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9bc7a1-1030-47b3-b81f-40fea4a0a457",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cac828-9be4-4dbd-9338-c9a1cee82805",
   "metadata": {},
   "source": [
    "All of these numbers match up with those in Spielman et al.'s paper except for one, which is reported as 0.65 in their paper rather as opposed to a 0.68 in our work. Since we checked that our data matches their provided output data, they likely made a simple typo when typing up their work for publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f8b93-2ae6-4a4f-8f60-7d36b282ffd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save file\n",
    "table2.to_csv( here(path[\"rtab\"],\"table2_weighted.csv\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b4520-bd4e-43ad-a6c5-8742416237f6",
   "metadata": {},
   "source": [
    "### RPr-H3\n",
    "\n",
    "Finally, we tested RPr-H3, that reproduced direction reversals and min, average, and max SoVI rank value of 28 demographic variables are not identical to the direction reversals and min, average, and max SoVI rank values shown in figure 2 of the original study.\n",
    "\n",
    "#### Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7efb4a2-1bbb-49c8-8513-3ebe6e0f61cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8c504-0feb-4c08-acec-150d866865c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save file\n",
    "summary_stats.to_csv( here(path[\"rtab\"],\"fig2_weighted.csv\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339e51a-da78-4e19-801b-45bf5fe8635c",
   "metadata": {},
   "source": [
    "As mentioned in the analysis, we eliminated the \"expected\" column and added minus signs to the variable labels where needed to make the figure more interpretable. \n",
    "The \"original\" column matches Spielman et al.'s exactly, but the \"reversals\" column has 2 minor differences: specifically, in Spielman et al.'s paper, QNOAUTO_ALT has 1 reversal instead of 0 and QEXTRCT_ALT has 7 reversals instead of 6. \n",
    "These are pretty minor differences. Because our variable_contributions dataset matches Spielman et al.'s data perfectly, our best guess is that the differences are due to transciption errors when they constructed their figure.\n",
    "\n",
    "Spielman et al. do not provide exact values for our last 4 columns, but everything looks accurate when we compare our numbers to their figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff6716-c3ce-46c6-9e9e-0e904fc3a20f",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "The goal of this study was to computationally reproduce Spielman et al.'s \"Evaluating social vulnerability indicators: criteria and their application to the Social Vulnerability Index\" (Spielman et al., 2020). \n",
    "To their credit, Spielman et al. provided their code, data, and metadata in their [sovi-validity GitHub repository](https://github.com/geoss/sovi-validity), making their analysis transparent, accessible, and reproducible in a manner that is rare in the field of geography.\n",
    "\n",
    "We have rejected RPr-H1, finding that our reproductions of each of 21 SoVI models were identical to the original results, with the possible exception of a few minor changes in county rank caused by very slightly different calculations of land area and population density.\n",
    "The implication of this finding is that the codified procedures used in this reproduction study can reliably reproduce and replicate the SoVI model.\n",
    "Given our rejection of RPr-H1, we were surprised to have difficulty exactly reproducing RPr-H2 and RPr-H3.\n",
    "Although our results were very similar to figure 1 and figure 2, we did find a few discrepancies in each figure which we can only assume are related to the data visualization process in the original study, which was not automated in code.\n",
    "\n",
    "\n",
    "In addition to checking the original study results, a major aim of this reproduction study was to improve its computational reproducibility.\n",
    "With all the necessary data and code in one GitHub repository, we assumed that the computational reproduction would be trivial. \n",
    "However, even with all of the resources they provided, we still spent a month of full-time work on this project before successfully reproducing their results. \n",
    "Our experiences working with this data motivated us to publish this report, so that we can share the obstacles that made the reproduction process so time-intensive and point out methods that researchers can employ to enhance the reproducibility of their work.\n",
    "\n",
    "The main obstacles that stood in the way of reproducing Spielman et al.'s results were:\n",
    "1. Outdated packages\n",
    "2. Extraneous data and code\n",
    "3. A confusing file system\n",
    "4. Incomplete code\n",
    "5. Our own edits\n",
    "\n",
    "#### Outdated packages\n",
    "\n",
    "The first obstacle, and one that we anticipated because much of Spielman et al.'s code was written 6 or 7 years ago, was the presence of outdated packages. \n",
    "When working with code developed on outdated packages, one has the option of adjusting their package versions or adapting your code to run on current package versions. \n",
    "We opted for the latter because we found no documentation regarding the package versions used by Spielman et al., and we hope to use our code in the future for a replication study, preferably operating on an up-to-date software environment.\n",
    "\n",
    "One notable package issue occurred because Spielman et al. wrote their code before the [refactoring of PySAL](https://github.com/pysal/pysal/wiki/PEP-13:-Refactor-PySAL-Using-Submodules) into several submodules that occured with the release of [PySAL 2.0.0](https://pypi.org/project/pysal/2.0.0/) in 2019.\n",
    "In Spielman et al.'s work, functions for calculating contiguity-based spatial weights were included in the PySAL package, but after the refactoring, this feature is included in the libpysal package.\n",
    "Without prior familiarity with the intricacies of PySAL's updates over the years, it took us some time to locate equivalent functions in the updated package.\n",
    "Changes to PySAL were perhaps the most time-consuming package update issue, but there were other smaller issues along the way, such as [Pandas's deprecation of the `.ix` indexer](https://pandas.pydata.org/pandas-docs/version/0.20/whatsnew.html) in favor of `.iloc` and `.loc`.\n",
    "Most edits due to package updates were small, but they all took some time to figure out, time that adds up.\n",
    "\n",
    "Researchers can eliminate this obstacle to reproducibility by containerizing their work.\n",
    "For this study in particular, we found that providing a list of required packages and their versions in a text file was sufficient to reconstruct the environment on another machine.\n",
    "\n",
    "#### Extraneous data and code\n",
    "\n",
    "Another issue that required a substantial amount of effort to overcome was the presence of extraneous data and code.\n",
    "For example, although Spielman et al.'s paper only mentions 5-year ACS data from 2012, in their `data_prep.py` file, they also import and manipulate decennial census variables.\n",
    "Unfortunately, they do not comment their code well-enough for other researchers to understand why they do this without combing through every line of code.\n",
    "After some close inspection, we found that all of the decennial variables except for land area are not used to generate their results, allowing us to discard unused data and a substantial amount of code.\n",
    "In their `data_prep.py` code, Spielman et al. also include some analysis of standard errors that we eventually discovered to be unnecessary.\n",
    "\n",
    "Several other files in Spielman et al.'s code folder also include extraneous code. \n",
    "In particular, the entire contents of the `drop1_place.py`, `spearman.py`, and `visualization.py`, as well as portions of `compute_sovis.py` implementing a drop1 analysis turned out to be unnecessary to generate the results they describe in their paper.\n",
    "It seems that Spielman et al. were considering several possible directions of research, and they left their dead ends in their code.\n",
    "We omit all of the unnecessary steps in our report, reducing the computational intensity of the analysis and making our work easier to follow.\n",
    "\n",
    "While the presence of unnecessary code may not have bothered the original authors of the paper, in the absence of comments explaining their purpose, extra code makes it far more difficult for an independent party to understand their work.\n",
    "If one does not quickly realize which parts of the code are actually necessary, they may spend time debugging code just to discard it later on, as we did.\n",
    "Researchers can make it much easier for others to reproduce their work by publishing a clean version of their code with informative comments and no extraneous work.\n",
    "\n",
    "#### Confusing file system\n",
    "\n",
    "From our experience working with Spielman et al.'s repository, we find that an index or some metadata regarding the structure of code and data would be beneficial.\n",
    "\n",
    "The code for Spielman et al.'s analysis was originally divided into 6 different python scripts:\n",
    "- `data_prep.py`\n",
    "- `spss_pca.py`\n",
    "- `drop1_place.py`\n",
    "- `compute_sovis.py`\n",
    "- `spearman.py`\n",
    "- `visualization.py`\n",
    "\n",
    "While one could infer the order of the scripts from the file names, file contents, and whether a file called any other files, that process took a fair amount of work and left room for error.\n",
    "When one script calls another script which calls another script, it can become difficult to locate the source of an error.\n",
    "Had the researchers provided an index explaining the purpose of each script and how they work together, like our `procedure_metadata.csv`, that would have reduced the confusion of working with multiple scripts and prevented us from even attempting to debug unnecessary scripts.\n",
    "Similarly, had the authors provided a quick summary of each of their data files, like our `data_metadata.csv`, then we would have quickly understood the purpose of each data source, instead of guessing at each's purpose based on its name and the code that manipulates it.\n",
    "Generally, the more information a researcher can provide about their data and code upfront, the less time other researchers will need to spend deciphering their files during a reproduction.\n",
    "\n",
    "#### Incomplete code\n",
    "\n",
    "While Spielman et al. provide all of the code required to reproduce their data files, they do not provide any code for reproducing their figures.\n",
    "By providing their code, data, and metadata in a GitHub repository, they are on the leading edge of reproducibility in geography.\n",
    "However, they could further improve reproducibility by including code to generate their figures.\n",
    "As noted in the results section, the output data files produced by our analysis and provided by Spielman et al. were identical, yet our figures exhibited slight differences.\n",
    "Had Spielman et al. provided code to produce their figures, it would be absolutely clear whether the differences between our figures were due to typos or a difference in code; and if the differences were typos, then producing their figures with code working directly from their data may have eliminated that issue altogether.\n",
    "\n",
    "#### Our own edits\n",
    "\n",
    "The other major time sink occurred because of our own edits.\n",
    "Spielman et al. provided data and metadata for reproducing their results; assuming that they acquired their data appropriately, this should be sufficient for a reproduction.\n",
    "However, our end-goal with this project is to produce a replication study that will potentially involve census data from multiple years.\n",
    "To facilitate the acquisition of analogous data in several different time periods, it is helpful to automate the process rather than manually downloading a large number of files.\n",
    "For this reason, we used the python package, [pygris](https://walker-data.com/pygris/), to acquire our data directly from the census via an API.\n",
    "Learning to use pygris and checking that our data sufficiently matches Spielman et al.'s data was a lengthy but worthy process, as it improves reproducibility and will be useful for our future work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d958961-6eec-4ba6-aaa2-c5e536033145",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "While there are ways that Spielman et al. could make it easier to reproduce their work, we were able to sufficiently reproduce every relevant output dataset.\n",
    "We find that their results to be legitimate, highlighting issues of internal and theoretical consistency with SoVI.\n",
    "\n",
    "Our main takeaway from reproducing Spielman et al.'s work is that merely providing one's code, data, and metadata is insufficient for allowing other researchers to quickly reproduce one's results.\n",
    "In particular, containerizing their software environment, cleaning their code and omitting extraneous information, providing some metadata regarding the structure of their code and data files, and including code for every step of the analysis from data acquisition to figure production would all enhance the reproducibility of their work.\n",
    "Spielman et al. produced a well-designed study in a reproducible repository, but a more carefully designed and fully executable research compendium would reduce the risk of transcription errors and allow researchers to reproduce their results in a more reasonable time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba380294-7bfe-4eff-b61c-4cba8caff739",
   "metadata": {},
   "source": [
    "## References\n",
    "- Cutter, S. L., Boruff, B. J., & Shirley, W. L. (2003). Social Vulnerability to Environmental Hazards. Social Science Quarterly, 84(2), 242–261. https://doi.org/10.1111/1540-6237.8402002\n",
    "- Rey, S. J., & Anselin, L. (2007). PySAL: A Python Library of Spatial Analytical Methods. Review of Regional Studies, 37(1). https://doi.org/10.52324/001c.8285\n",
    "- Spielman, S. E., Tuccillo, J., Folch, D. C., Schweikert, A., Davies, R., Wood, N., & Tate, E. (2020). Evaluating Social Vulnerability Indicators: Criteria and their Application to the Social Vulnerability Index. Natural Hazards, 100(1), 417–436. https://doi.org/10.1007/s11069-019-03820-z\n",
    "\n",
    "## Funding\n",
    "- `Funding Name`: NSF Directorate for Social, Behavioral and Economic Sciences\n",
    "- `Funding Title`: Transforming theory-building and STEM education through reproductions and replications in the geographical sciences\n",
    "- `Award info URI`: https://www.nsf.gov/awardsearch/showAward?AWD_ID=2049837\n",
    "- `Award number`: BCS-2049837"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
